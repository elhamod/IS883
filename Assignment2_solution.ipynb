{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGwQeMHQqY_3"
      },
      "source": [
        "#**Using Transformers for language modeling**\n",
        "\n",
        "In this assignment, you will experiment with using transformers to solve two different language modeling roblems: Text generation and translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUd9MZg95E79"
      },
      "source": [
        "- Some packages you may need. You are free to use alternative ones, but this should make your task simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hUKJ_GcK5Ela",
        "outputId": "ae6e1526-31b2-4163-d2fd-06bcd99d3f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: apache_beam in /usr/local/lib/python3.10/dist-packages (2.51.0)\n",
            "Requirement already satisfied: mwparserfromhell in /usr/local/lib/python3.10/dist-packages (0.6.5)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.9.10)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache_beam)\n",
            "  Using cached dill-0.3.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.9.0)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.59.2)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.22.0)\n",
            "Requirement already satisfied: js2py<1,>=0.74 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.74)\n",
            "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.23.5)\n",
            "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.6.1)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (23.2)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.6.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.0,!=4.24.1,!=4.24.2,<4.25.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2023.3.post1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2023.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.5.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.22.0)\n",
            "Requirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (9.0.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (0.6.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.1.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache_beam) (5.2)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache_beam) (2.7.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache_beam) (2.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2023.7.22)\n",
            "Installing collected packages: dill\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.7\n",
            "    Uninstalling dill-0.3.7:\n",
            "      Successfully uninstalled dill-0.3.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dill-0.3.1.1\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Collecting dill (from evaluate)\n",
            "  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: dill\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.1.1\n",
            "    Uninstalling dill-0.3.1.1:\n",
            "      Successfully uninstalled dill-0.3.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.51.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dill-0.3.7\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# You only need to run this once when you load the notebook to install required packages. You can comment this cell out once you run it.\n",
        "\n",
        "# !pip install torch\n",
        "!pip install datasets\n",
        "!pip install apache_beam mwparserfromhell\n",
        "!pip install transformers[torch]\n",
        "!pip install sentence_transformers\n",
        "!pip install evaluate\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a33z_MdOdvN"
      },
      "source": [
        "Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEyFXeXQOWP7",
        "outputId": "4c886eba-d148-48e8-b053-0258f71df3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8CUJw2KAMSC"
      },
      "source": [
        "- Check if GPU is available. If so, it should print `cuda`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EmBx6OTIAJFb",
        "outputId": "133f9bf0-864d-44eb-dd10-b139b5c04439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOEHB0JR1wyc"
      },
      "source": [
        "##**Part 1: Using a Transformer to model Wikipedia text**\n",
        "\n",
        "You will use a GPT2 Transformer to model the data [simple Wikipedia dataset](https://huggingface.co/datasets/wikipedia/viewer/20220301.simple/train). Our goal is to generate Wikipedia-sounding articles that sound novel but also believable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWMD0fOF5Zuh"
      },
      "source": [
        "- Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWVmDdrq5Y9e",
        "outputId": "34cf2bb2-7510-4658-b555-919e01531550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset structure is DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'url', 'title', 'text'],\n",
            "        num_rows: 205328\n",
            "    })\n",
            "})\n",
            "an example of a training sequence is:  April is the fourth month of the year in the Julian and Gregorian calendars, and comes between March and May. It is one of four months to have 30 days.\n",
            "\n",
            "April always begins on the same day of week as July, and additionally, January in leap years. April always ends on the same day of the week as December.\n",
            "\n",
            "April's flowers are the Sweet Pea and Daisy. Its birthstone is the diamond. The meaning of the diamond is innocence.\n",
            "\n",
            "The Month \n",
            "\n",
            "April comes between March and May, making it the fourth month of the year. It also comes first in the year out of the four months that have 30 days, as June, September and November are later in the year.\n",
            "\n",
            "April begins on the same day of the week as July every year and on the same day of the week as January in leap years. April ends on the same day of the week as December every year, as each other's last days are exactly 35 weeks (245 days) apart.\n",
            "\n",
            "In common years, April starts on the same day of the week as October of the previous year, and in leap years, May of the previous year. In common years, April finishes on the same day of the week as July of the previous year, and in leap years, February and October of the previous year. In common years immediately after other common years, April starts on the same day of the week as January of the previous year, and in leap years and years immediately after that, April finishes on the same day of the week as January of the previous year.\n",
            "\n",
            "In years immediately before common years, April starts on the same day of the week as September and December of the following year, and in years immediately before leap years, June of the following year. In years immediately before common years, April finishes on the same day of the week as September of the following year, and in years immediately before leap years, March and June of the following year.\n",
            "\n",
            "April is a spring month in the Northern Hemisphere and an autumn/fall month in the Southern Hemisphere. In each hemisphere, it is the seasonal equivalent of October in the other.\n",
            "\n",
            "It is unclear as to where April got its name. A common theory is that it comes from the Latin word \"aperire\", meaning \"to open\", referring to flowers opening in spring. Another theory is that the name could come from Aphrodite, the Greek goddess of love. It was originally the second month in the old Roman Calendar, before the start of the new year was put to January 1.\n",
            "\n",
            "Quite a few festivals are held in this month. In many Southeast Asian cultures, new year is celebrated in this month (including Songkran). In Western Christianity, Easter can be celebrated on a Sunday between March 22 and April 25. In Orthodox Christianity, it can fall between April 4 and May 8. At the end of the month, Central and Northern European cultures celebrate Walpurgis Night on April 30, marking the transition from winter into summer.\n",
            "\n",
            "April in poetry \n",
            "Poets use April to mean the end of winter. For example: April showers bring May flowers.\n",
            "\n",
            "Events in April\n",
            "\n",
            "Fixed Events \n",
            "\n",
            " April 1 - April Fools' Day\n",
            " April 1 - Islamic Republic Day (Iran)\n",
            " April 2 - International Children's Book Day\n",
            " April 2 - Thai Heritage and Conservation Day\n",
            " April 2 - World Autism Awareness Day\n",
            " April 2 - Malvinas Day (Argentina)\n",
            " April 4 - Independence Day (Senegal)\n",
            " April 4 - International Day for Landmine Awareness and Assistance\n",
            " April 4 - Peace Day (Angola)\n",
            " April 5 - End of Tax Year (United Kingdom)\n",
            " April 6 - Tartan Day (Canada and United States)\n",
            " April 6 - Chakri Day (Thailand)\n",
            " April 7 - Day of Maternity and Beauty (Armenia)\n",
            " April 7 - Genocide Memorial Day (Rwanda)\n",
            " April 7 - World Health Day\n",
            " April 7 - Women's Day (Mozambique)\n",
            " April 8 - Buddha's Birthday (Buddhism)\n",
            " April 9 - Martyrs' Day (Tunisia)\n",
            " April 9 - Day of National Unity (Georgia)\n",
            " April 9 - Day of the Finnish language\n",
            " April 12 - Cosmonauts' Day (Russia), marking the day of Yuri Gagarin's space flight\n",
            " April 13 - Songkan (Laos), local New Year celebration\n",
            " April 13 - Cambodian New Year\n",
            " April 13 - Thomas Jefferson's Birthday (United States)\n",
            " April 14 - Southeast Asian New Year festivals, including Songkran\n",
            " April 14 - Georgian language Day\n",
            " April 14 - Youth Day (Angola)\n",
            " April 14 - Ambedkar Tayanti (India)\n",
            " April 14 - Pan-American Day\n",
            " April 15 - Tax Day (United States)\n",
            " April 15 - Kim Il-Sung's Birthday (North Korea)\n",
            " April 15 - Father Damien Day (Hawaii)\n",
            " April 15 - Jackie Robinson Day (Major League Baseball)\n",
            " April 16 - Birthday of Queen Margrethe II of Denmark\n",
            " April 16 - Emancipation Day (Washington, DC)\n",
            " April 16 - World Voice Day\n",
            " April 16 - Selena Day (Texas)\n",
            " April 17 - National Day of Syria\n",
            " April 17 - Flag Day (American Samoa)\n",
            " April 17 - Women's Day (Gabon)\n",
            " April 17 - World Hemophilia Day\n",
            " April 18 - Independence Day (Zimbabwe)\n",
            " April 18 - Invention Day (Japan)\n",
            " April 18 - International Day of Monuments and Sites\n",
            " April 19 - Bicycle Day\n",
            " April 19 - Dutch-American Friendship Day\n",
            " April 19 - Birthday of King Mswati III of Swaziland\n",
            " April 19 - Patriots' Day (Massachusetts, Maine, Wisconsin)\n",
            " April 20 - 4/20 in Cannabis Culture\n",
            " April 21 - John Muir Day (California)\n",
            " April 21 - San Jacinto Day (Texas)\n",
            " April 21 - Kartini Day (Indonesia)\n",
            " April 21 - National Tree Planting Day (Kenya)\n",
            " April 21 - First Day of Ridran (Baha'i faith)\n",
            " April 21 - Grounation Day (Rastafari movement)\n",
            " April 22 - Earth Day\n",
            " April 22 - Discovery Day (Brazil)\n",
            " April 23 - Saint George's Day, celebrating the patron saint of several countries, regions and cities (including England and Catalonia)\n",
            " April 23 - World Book Day\n",
            " April 23 - National Sovereignty and Children's Day (Turkey)\n",
            " April 24 - Democracy Day (Nepal)\n",
            " April 24 - Genocide Day (Armenia)\n",
            " April 24 - Republic Day (the Gambia)\n",
            " April 25 - Australia and New Zealand celebrate ANZAC Day. ANZAC  means Australian and New Zealand Army Corps, and began in 1915.\n",
            " April 25 - World DNA Day\n",
            " April 25 - World Malaria Day\n",
            " April 25 - Flag Day (Swaziland, Faroe Islands)\n",
            " April 25 - Freedom Day (Portugal)\n",
            " April 25 - Liberation Day (Italy)\n",
            " April 25 - Army Day (North Korea)\n",
            " April 26 - Union Day (Tanzania)\n",
            " April 26 - Confederate Memorial Day (Texas, Florida)\n",
            " April 27 - Independence Day (Sierra Leone and Togo)\n",
            " April 27 - Freedom Day (South Africa)\n",
            " April 27 - World Tapir Day\n",
            " April 27 - King's Day (Netherlands) from 2014, birthday of Willem-Alexander of the Netherlands\n",
            " April 28 - Workers Memorial Day\n",
            " April 28 - National Day (Sardinia)\n",
            " April 28 - National Heroes Day (Barbados)\n",
            " April 29 - Showa Day (Japan), birthday of Emperor Hirohito, who died in 1989\n",
            " April 29 - International Dance Day\n",
            " April 30 - Former Queen's Day Holiday in the Netherlands (changed to King's Day, April 27 in 2014), was the birthday of former Queen Juliana of the Netherlands\n",
            " April 30 - Flag Day in Sweden (birthday of King Carl XVI Gustaf of Sweden)\n",
            " April 30 - International Jazz Day\n",
            " April 30 - Walpurgis Night (Central and Northern Europe)\n",
            "\n",
            "Moveable Events \n",
            "\n",
            " Easter-related events in Western Christianity:\n",
            " Palm Sunday (between March 15 and April 18)\n",
            " Maundy Thursday (between March 19 and April 22)\n",
            " Good Friday (between March 20 and April 23)\n",
            " Easter Sunday (between March 22 and April 25)\n",
            " Easter Monday (between March 23 and April 26)\n",
            " Eastern Orthodox Easter falls between April 4 and May 8.\n",
            " Ascension Day (Western Christianity), falls between April 30 and June 3.\n",
            " Jewish Passover - falls in the same week as Western Christianity's Holy Week, which is the week leading up to Easter.\n",
            " Mother's Day (UK) falls between March 1 and April 4.\n",
            " World Snooker Championship (late April, early May)\n",
            " Horse racing - Grand National (UK), Kentucky Derby (United States)\n",
            " Start of Daylight Saving Time - Clocks going forward one hour:\n",
            " Most of Mexico\n",
            " Morocco (Ramadan does not include Daylight Saving Time)\n",
            " End of Daylight Saving Time - Clocks going back one hour:\n",
            " Southeast Australia, and New Zealand\n",
            " Chile\n",
            " Marathon Events in the following cities:\n",
            " Belgrade, Serbia\n",
            " Boston, Massachusetts, United States\n",
            " Brighton, United Kingdom\n",
            " Enschede, Netherlands\n",
            " London, United Kingdom\n",
            " Madrid, Spain\n",
            " Paris, France\n",
            " Rotterdam, Netherlands\n",
            " Utrecht, Netherlands\n",
            " Zurich, Switzerland\n",
            "\n",
            "Selection of Historical Events \n",
            "\n",
            " April 1, 1918 - The Royal Air Force is founded.\n",
            " April 1, 1976 - Apple Inc. is founded.\n",
            " April 1, 1979 - The Islamic Republic of Iran is founded.\n",
            " April 1, 1999 - The territory of Nunavut is created in Northern Canada.\n",
            " April 1, 2001 - The Netherlands introduces same-sex marriage, as the first country to do so.\n",
            " April 2, 1519 - Florida is sighted by a European for the first time.\n",
            " April 2, 1930 - Haile Selassie becomes Emperor of Ethiopia.\n",
            " April 2, 1982 - Start of the Falklands War, as Argentine forces land on the Falkland Islands.\n",
            " April 2, 2005 - Pope John Paul II dies aged 84, after 26-and-a-half years as Pope.\n",
            " April 3, 1973 - The first-ever mobile phone call is placed by Martin Cooper in New York City.\n",
            " April 4, 1721 - Robert Walpole becomes the first Prime Minister of Great Britain.\n",
            " April 4, 1841 - William Henry Harrison dies. He was President of the United States for 31 days, the shortest-ever time in office for a US President.\n",
            " April 4, 1960 - Senegal becomes independent.\n",
            " April 4, 1968 - Assassination of Martin Luther King, Jr. in Memphis, Tennessee.\n",
            " April 5, 1722 - Jacob Roggeveen becomes the first European to land on Easter Island, landing there on Easter Sunday.\n",
            " April 6, 1320 - Scotland's independence is confirmed with the Declaration of Arbroath.\n",
            " April 6, 1830 - The Mormon Church is founded.\n",
            " April 6, 1909 - Robert Peary claims to have been first at the North Pole on this date.\n",
            " April 7, 1994 - The Rwandan Genocide begins.\n",
            " April 9, 1865 - American Civil War: Confederate forces under Robert E. Lee surrender to Union forces.\n",
            " April 9, 1940 - World War II: Denmark and Norway are invaded by Nazi Germany.\n",
            " April 9, 1989 - April 9 tragedy: In Tbilisi, Georgia, a peaceful demonstration for independence is broken up by the Soviet Army, killing 20 people. The country gains independence on this date exactly two years later.\n",
            " April 10, 1815 - Mount Tambora in Indonesia erupts in a huge eruption, affecting the world's climate for at least a year.\n",
            " April 10, 2010 - A plane crash near Smolensk, Russia, kills several people who were important in Poland, including President Lech Kaczynski.\n",
            " April 11, 1814 - Napoleon Bonaparte is exiled to the island of Elba.\n",
            " April 11, 1954 - Said to have been the most boring day of the 20th century.\n",
            " April 12, 1861 - The American Civil War begins at Fort Sumter, Charleston, South Carolina.\n",
            " April 12, 1945 - US President Franklin D. Roosevelt dies, and Harry S. Truman replaces him.\n",
            " April 12, 1961 - Yuri Gagarin becomes the first human to fly into space.\n",
            " April 14, 1865 - US President Abraham Lincoln is shot dead at Ford's Theatre by John Wilkes Booth. Lincoln dies the next day.\n",
            " April 14, 2010 - Qinghai Province, China, is hit by an earthquake, killing tens of thousands of people.\n",
            " April 14, 2010 - The eruption of Eyjafjallajokull in Iceland shuts down air traffic around Europe for a week, due to its ash cloud.\n",
            " April 15, 1912 - The ship RMS Titanic sinks near Newfoundland after hitting an iceberg, resulting in the deaths of many of the people on board.\n",
            " April 16, 1943 - Albert Hofmann discovers LSD's effects.\n",
            " April 17, 1946 - Syria gains full independence from France.\n",
            " April 18, 1906 - 1906 San Francisco earthquake: San Francisco, California, is hit by a big earthquake, resulting in fires that destroy large parts of the city.\n",
            " April 18, 1980 - Zimbabwe gains full independence.\n",
            " April 19, 1897 - The first Boston Marathon is held.\n",
            " April 19, 1971 - Sierra Leone becomes a republic.\n",
            " April 19, 1993 - The siege of the Branch Davidians at Waco, Texas, ends in a fire that kills 82 people.\n",
            " April 19, 1995 - Timothy McVeigh carries out the Oklahoma City bombing, killing 169 people.\n",
            " April 19, 2005 - Joseph Alois Ratzinger becomes Pope Benedict XVI.\n",
            " April 20, 1902 - Marie Curie and Pierre Curie refine Radium.\n",
            " April 20, 2010 - Deepwater Horizon oil spill: A massive fire on the Deepwater Horizon drilling rig in the Gulf of Mexico kills 11 workers and causes a massive oil spill, the worst spill in US history.\n",
            " April 21, 753 BC - Legendary founding date of Rome\n",
            " April 21, 1509 - Henry VIII of England becomes King.\n",
            " April 21, 1908 - Frederick Cook claims to have reached the North Pole on this date.\n",
            " April 22, 1502 - Pedro Alvares Cabral becomes the first European to reach present-day Brazil.\n",
            " April 22, 1970 - Earth Day is observed for the first time.\n",
            " April 23, 1533 - The Church of England declares that Henry VIII of England and Catherine of Aragon are not married.\n",
            " April 24, 1916 - The Easter Rising occurs in Dublin, Ireland.\n",
            " April 24, 1990 - The Hubble Space Telescope is launched on the Space Shuttle Discovery.\n",
            " April 25, 1915 - World War I: In Turkey, the Battle of Gallipoli begins, Australian, French, British and New Zealand forces land at Anzac cove.\n",
            " April 25, 1974 - Portugal's dictatorship is overthrown in a coup, in what is known as the Carnation Revolution.\n",
            " April 26, 1937 - Spanish Civil War: German planes bomb the town of Guernica, Basque Country, later depicted in a painting by Pablo Picasso.\n",
            " April 26, 1964 - Tanganyika and Zanzibar merge to form Tanzania.\n",
            " April 26, 1986 - A reactor explosion occurs at the Chernobyl nuclear plant in present-day Ukraine, with radiation spreading around Europe and the world.\n",
            " April 26/27, 1994 - South Africa holds its first free elections.\n",
            " April 27, 1960 - Togo becomes independent from France.\n",
            " April 27, 1961 - Sierra Leone becomes independent from the United Kingdom.\n",
            " April 28, 1789 - Mutiny on the ship Bounty in the Pacific Ocean, lead by Fletcher Christian.\n",
            " April 28, 1945 - Benito Mussolini is executed by Italian partisans.\n",
            " April 28, 1947 - In Peru, Thor Heyerdahl starts his Kon-Tiki expedition aimed at proving his theory that the Polynesian settlers on the Pacific Ocean's islands came from South America.\n",
            " April 29, 1991 - A cyclone in Bangladesh kills an estimated 138,000 people.\n",
            " April 29, 2011 - The wedding of Prince William, Duke of Cambridge and Catherine, Duchess of Cambridge is broadcast worldwide.\n",
            " April 30, 1789 - George Washington becomes the first President of the United States.\n",
            " April 30, 1803 - The United States purchases (buys) the Louisiana territory from France.\n",
            " April 30, 1945 - Adolf Hitler commits suicide on the same day that the Soviet Army raises the Red Flag on Berlin's Reichstag.\n",
            " April 30, 1952 - The Diary of Anne Frank is published in English.\n",
            " April 30, 1975 - The Vietnam War ends, as North Vietnamese forces take Saigon.\n",
            " April 30, 1980 - Queen Juliana of the Netherlands abdicates the throne, and her daughter becomes Queen Beatrix of the Netherlands. Beatrix later also abdicates, on this day in 2013, in favor of her son, King Willem-Alexander of the Netherlands.\n",
            "\n",
            "Trivia \n",
            "\n",
            " In Western Christianity, there is a bigger likelihood of Easter falling in April than in March.\n",
            " The months around April (March and May) both start with an 'M' in the English language, with an 'A' as the second letter.\n",
            " In the English language, April is the first of three months in-a-row, along with May and June, that is also a female given name.\n",
            " The astrological signs for April are Aries (March 21 to April 20) and Taurus (April 21 to May 20).\n",
            " The sweet pea and daisy are the traditional birth flowers for April.\n",
            " Birthstone for April is the Diamond.\n",
            "April 1 is the only day in April to start within the first quarter of the calendar year.\n",
            " If the months of the year were arranged in alphabetical order in the English language, April would come first.\n",
            " Six current European monarchs were born in April. They are King Philippe of Belgium (April 15), Queen Margrethe II of Denmark (April 16), Henri, Grand Duke of Luxembourg (April 16), Elizabeth II of the United Kingdom and Commonwealth realms (April 21), King Willem-Alexander of the Netherlands (April 27), and King Carl XVI Gustaf of Sweden (April 30).\n",
            "\n",
            "References\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "wikipedia_simple_dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n",
        "\n",
        "print(\"dataset structure is\", wikipedia_simple_dataset)\n",
        "\n",
        "print(\"an example of a training sequence is: \", wikipedia_simple_dataset[\"train\"][\"text\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdKDU7ao5n9i"
      },
      "source": [
        "- Split the dataset into a training set (the first 300 articles) and a the test set (the last 60 articles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "k_2Kl4fl5p-z"
      },
      "outputs": [],
      "source": [
        "# Check the total number of rows in the dataset\n",
        "total_rows = len(wikipedia_simple_dataset[\"train\"])\n",
        "\n",
        "# Define the indices for splitting the dataset\n",
        "train_end_idx = 300  # The end index for the training set\n",
        "test_start_idx = total_rows - 60  # The start index for the test set\n",
        "\n",
        "# Ensure the dataset has at least 12k rows\n",
        "if total_rows < 360:\n",
        "    raise ValueError(\"The dataset has fewer than 360 rows.\")\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_dataset = wikipedia_simple_dataset[\"train\"].select(range(train_end_idx))\n",
        "test_dataset = wikipedia_simple_dataset[\"train\"].select(range(test_start_idx, total_rows))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v4vZaLA25PT"
      },
      "source": [
        "1. **(1 point)** Start from a *pretrained* GPT2 transformer with a context of 512 tokens with padding, such that:\n",
        "  - Print the training and test losses every epoch. **(0.25 points)**\n",
        "  - Save the model that performs best on the **test set** as `best_model`  **(0.25 points)**\n",
        "  - Train for 10 epochs **(0.5 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvgypv9xPb6o"
      },
      "source": [
        "Step 1: Create the tokenizer and tokenize the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "XQcpC8QeCc86"
      },
      "outputs": [],
      "source": [
        "context_len = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Rt5OS4Bs96AA"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "#Tokenization\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token # Alternatively, other special tokens could be used. These tokens are just used to pad the context up to the context length incase your text is short.\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, max_length=context_len, padding='max_length')\n",
        "\n",
        "train_dataset_tokenized = train_dataset.map(tokenize_function)\n",
        "test_dataset_tokenized = test_dataset.map(tokenize_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omQv2LZ1nVgp",
        "outputId": "9305d61a-cf3e-4369-b6bc-5d1b6b545649"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'url', 'title', 'text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 60\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Taking a look at the headers of the tokenized dataset\n",
        "# We only really care about 'text' and 'input_ids', which is the tokenized text.\n",
        "test_dataset_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6CsE3KGSTkN"
      },
      "source": [
        "Step 2: Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tRE91bfa-Ewb"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq5ojgD0S1Ha"
      },
      "source": [
        "Step 3: Create a perplexity metric and a `compute_metric` function to measure the perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "G8WdV9AZ_KlV"
      },
      "outputs": [],
      "source": [
        "#NOTE: The function below calculates perplexity for each iteration. It is not meant to be used for calculating the complexity on the test set at the end.\n",
        "\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "\n",
        "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Decode the predictions to get the predicted text\n",
        "    predicted_text = [tokenizer.decode(p) for p in predictions]\n",
        "\n",
        "    return {\"perplexity\": perplexity.compute(predictions=predicted_text, model_id='gpt2')['mean_perplexity']}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu3_DYhvTMZQ"
      },
      "source": [
        "Step 4: Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "N341Rjsd-J0y"
      },
      "outputs": [],
      "source": [
        "#training\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2, # Setting the batch size low helps with memory issues.\n",
        "    per_device_eval_batch_size=2, # Setting the batch size low helps with memory issues.\n",
        "    logging_dir='./pre_trained/logs',\n",
        "    evaluation_strategy=\"epoch\", # Setting this to \"epoch\" instead of \"step\" speeds up the training because evaluations are not made for every batch.\n",
        "    logging_strategy=\"epoch\", # Setting this to \"epoch\" instead of \"step\" speeds up the training because logging is not made for every batch.\n",
        "    save_strategy=\"epoch\", # Model saving happens at the epoch level, which is more efficient than at the batch level.\n",
        "    save_total_limit=1,  # Only save the best model\n",
        "    output_dir=\"./pre_trained/results\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    # learning_rate=5e-4,\n",
        "    num_train_epochs=10, # Sets number of epochs to 10.\n",
        "    load_best_model_at_end=True, # IMPORTANT: this is what loads the best model at the end of training.\n",
        "    metric_for_best_model=\"eval_loss\", # Optional as \"eval_loss\" is the default value, but emphasizes that we care about best on \"eval\" set, not train set.\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False) # Handles padding the different texts to make them all same lengths and batchable.\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset_tokenized,\n",
        "    eval_dataset=test_dataset_tokenized,\n",
        "    # compute_metrics=compute_metrics  # This line calls compute_metrics to compute the perplexity per epoch. However, in case you are having memory issues, it could be commented out for better efficiency.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iRQDYNUwD-N4",
        "outputId": "64be3767-b35d-4213-a5eb-bb739553e86f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 10:56, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.977400</td>\n",
              "      <td>3.270028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.668600</td>\n",
              "      <td>3.298128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.462800</td>\n",
              "      <td>3.363056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.304900</td>\n",
              "      <td>3.433841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.183400</td>\n",
              "      <td>3.501757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.073100</td>\n",
              "      <td>3.573758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.988100</td>\n",
              "      <td>3.630997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.920100</td>\n",
              "      <td>3.668010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.872000</td>\n",
              "      <td>3.703483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.827000</td>\n",
              "      <td>3.730242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=2.2277340698242187, metrics={'train_runtime': 656.8152, 'train_samples_per_second': 4.567, 'train_steps_per_second': 2.284, 'total_flos': 783876096000000.0, 'train_loss': 2.2277340698242187, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2fBhnfxLhSW"
      },
      "source": [
        "Step 5: Save the best model to your Google Drive to path `/content/drive/MyDrive/IS883_HW2/best_model_wiki`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "jbuIS2VO-X1_"
      },
      "outputs": [],
      "source": [
        "saved_model_name = \"/content/drive/MyDrive/IS883_HW2/wiki_best_model\"\n",
        "\n",
        "trainer.save_model(saved_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL-MPDXxOB-I"
      },
      "source": [
        "Step 6: Now load the model back and assign it to `best_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "RkFlfyNFL5Hi"
      },
      "outputs": [],
      "source": [
        "best_model = GPT2LMHeadModel.from_pretrained(saved_model_name).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EocqT3zA54Ec"
      },
      "source": [
        "2. **(1 point)** Write a function that generates text using `best_model`. This function takes the following parameters **(0.25 points)**:\n",
        "\n",
        "  - *temperature*: has a default value 1.0.\n",
        "  - *max_gen_tokens*: specifies the maximum number of tokens in the generated text. Default value is 40.\n",
        "  - *prefix*: default value `tokenizer.bos_token` (i.e., beginning of sentence token).\n",
        "\n",
        "Each time the function is called, it generates 5 possible unique texts. Also, use sampling to avoid generating identical texts. **(0.25 points)**\n",
        "\n",
        "Use the function and generate some texts with different temperatures and prefixes. Comment on the quality of the model. **(0.5 points)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "xaqapc5R8nlm"
      },
      "outputs": [],
      "source": [
        "def gen_text(model, temperature=1.0, max_gen_tokens=40, prefix=tokenizer.bos_token):\n",
        "\n",
        "  # Tokenize input text\n",
        "  inputs = tokenizer(prefix, return_tensors=\"pt\", truncation=True, max_length=context_len, return_special_tokens_mask=True)\n",
        "\n",
        "  # Move inputs to GPU\n",
        "  inputs = {name: tensor.to(model.device) for name, tensor in inputs.items()}\n",
        "\n",
        "  # Generate text using the best model\n",
        "  output_ids = model.generate(inputs[\"input_ids\"],\n",
        "                              # no_repeat_ngram_size=5,\n",
        "                              num_return_sequences=5, # Returns 5 texts as asked above\n",
        "                              attention_mask=inputs[\"attention_mask\"],\n",
        "                              max_new_tokens=max_gen_tokens,\n",
        "                              temperature=temperature,\n",
        "                              pad_token_id=tokenizer.pad_token_id,\n",
        "                              do_sample=True) # IMPORTANT: You need to turn sampling on. Otherwise, you will always get the same generated text.\n",
        "\n",
        "  # print the sentences out\n",
        "  for i in range(5):\n",
        "    print('----')\n",
        "\n",
        "    # Decode the generated text\n",
        "    generated_text = tokenizer.decode(output_ids[i].tolist(), skip_special_tokens=True)\n",
        "\n",
        "    print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPJl5QHT7WAq"
      },
      "source": [
        "Call the function here to generate 5 different texts. The texts should not be identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w-VaR48j7fgC",
        "outputId": "9d97da00-472c-4a68-80a8-19e2f515b31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "'The idea of this would have to have been completely different' he told KAIT (Kabila), explaining the 'how a new person would find that same motivation in a new person\n",
            "----\n",
            "A year-long investigation by The New York Times found that the number of people arrested for sex crimes increased for every court-ordered misdemeanor count, up $12.5 million compared to the same period\n",
            "----\n",
            "\n",
            "The U.S. Defense Information Agency, which provides the spy agency with information about military threats, has recently been criticized for revealing sensitive information about American civilian casualties during the Syrian war, but has\n",
            "----\n",
            "- Updated for July 22-1922\n",
            "\n",
            "After years of debate on how the state must comply with the State Constitution, California Supreme Court judge Barry Lee ruled last July 22 that the state did have\n",
            "----\n",
            "There had been several changes of the state of Arkansas last year, especially with our current government.\n",
            "\n",
            "I know we are moving a lot of money, but if they can provide some new tax breaks\n"
          ]
        }
      ],
      "source": [
        "gen_text(best_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_text(best_model, temperature=1, max_gen_tokens=100, prefix=\"Robert Walpole\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SrWyfNAWZ8W0",
        "outputId": "3fa40c8d-e09e-49fb-f1d6-6d6c787474ef"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "Robert Walpole / Staff Photographer A large tent with a plastic-wrapped table rests atop the makeshift bed.\n",
            "\n",
            "A large tent with a plastic-wrapped table rests atop the makeshift bed.\n",
            "\n",
            "A massive tent is mounted on a large wooden crate, and there is also a smaller bed for sleeping under.\n",
            "\n",
            "These tents have a small wooden seat up top for the tent.\n",
            "\n",
            "A large tent is mounted on a large wooden crate and there is also a smaller bed for sleeping under.\n",
            "\n",
            "----\n",
            "Robert Walpole, author of \"The End of the World\": Obama and Globalism by Stephen Walt Jr.\n",
            "\n",
            "H/T Daily Beast\n",
            "----\n",
            "Robert Walpole/Getty Images\n",
            "\n",
            "The Seahawks' offense played solid but didn't quite come close to reaching the point of being a true playoff contender at least in the way Washington's defense played the previous month. The Seahawks won a game by 13 points in a 20-point loss to the New Vikings earlier in the day. However, they didn't have the opportunity they had in the NFC East to make an impact. They simply lost to the Vikings with a 25-13 win before the season had turned into\n",
            "----\n",
            "Robert Walpole in the UK and American writers of the 1950s including Henry James and John Milton and Robert Spencer and William Morrissey and many more, are also thought to be associated with Tolkien.\n",
            "\n",
            "In 2006 a Tolkien scholar published an article entitled \"Who Are You?\" that suggested Tolkien and other famous authors such as Tolkien's sister-in-law, Stephen King were also involved in the development of the concept. The article then went on to speculate on some of the more popular characters of Tolkien's works,\n",
            "----\n",
            "Robert Walpole, M.D., and Joseph C. Erikson, R.I., \"Microbial Growth at Early Dienstland-Geschied (GDSG) and Mesozoic Era Periodic Carbonatrich at Basalt Lake,\" Journal of Geophysical Research: Solid Earth, 67(5-6), 2016\n",
            "\n",
            "Aquarius, C. M., Y. B. DeLeon, J. K. Fischbach, M. G. Kondas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_text(best_model, temperature=0.2, max_gen_tokens=100, prefix=\"Robert Walpole\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nhUGe-dfPGqq",
        "outputId": "e4a38a3a-41dc-42c0-d4a7-86b598ece677"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "Robert Walpole, a former president of the American Civil Liberties Union, said the bill would \"make it harder for people to get jobs.\"\n",
            "\n",
            "\"It's going to make it harder for people to get jobs,\" he said. \"It's going to make it harder for people to get jobs.\"\n",
            "\n",
            "The bill would also allow employers to deny benefits to people who have been convicted of a felony, and would require them to pay a penalty of up to $500 for each conviction.\n",
            "\n",
            "The bill\n",
            "----\n",
            "Robert Walpole, a former U.S. ambassador to the United Nations, said the U.S. was \"deeply concerned\" about the situation in Syria.\n",
            "\n",
            "\"We are concerned about the situation in Syria and we are concerned about the situation in Iraq,\" Walpole said. \"We are concerned about the situation in Syria and we are concerned about the situation in Iraq.\"\n",
            "\n",
            "The U.S. has been sending troops to Syria to help fight the Islamic State, which has seized large sw\n",
            "----\n",
            "Robert Walpole, a former U.S. ambassador to the United Nations, said that the U.S. was \"not going to be able to do anything to stop it.\"\n",
            "\n",
            "\"We're going to have to do something about it,\" he said.\n",
            "\n",
            "The U.S. has been accused of using drones to spy on U.S. citizens, but the U.S. has denied that it has used drones to spy on U.S. citizens.\n",
            "\n",
            "\"We have\n",
            "----\n",
            "Robert Walpole, a former U.S. ambassador to China, said the U.S. should \"take a hard look at the situation in China and the situation in the region.\"\n",
            "\n",
            "\"We should take a hard look at the situation in China and the situation in the region,\" Walpole said. \"We should take a hard look at the situation in China and the situation in the region.\"\n",
            "\n",
            "The U.S. has been accused of sending a \"very strong signal\" to China that\n",
            "----\n",
            "Robert Walpole, the former chief of staff to President George W. Bush, said that the administration had \"no choice but to take action\" to protect the nation's national security.\n",
            "\n",
            "\"We are not going to let the president's actions get in the way of our national security,\" Walpole said. \"We are going to take action to protect our national security.\"\n",
            "\n",
            "The administration has also been criticized for its handling of the Benghazi attack, which left four Americans dead.\n",
            "\n",
            "The administration has\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_text(best_model, temperature=1.7, max_gen_tokens=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KBSsbuS6PLZC",
        "outputId": "11b8f261-62f2-45af-9a98-ae9399307582"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            ", the state where it was used for public works\n",
            "\n",
            "and construction. (It started its own project in 2012 after state officials failed and it ended this summer, with a $50 million purchase. That investment has yielded some new and \"supervised labor.\" Now you got some bad bad ones here. And it takes years-term fixes as engineers add features and improvements before its day starts getting bigger and grayer.) Many cities around New England got a lot right. Other companies saw better pay\n",
            "----\n",
            "Boom is just the latest example of many of the challenges associated with tackling \"Big Blue Hearts.\" First and foremost, it helps ensure every child feels safe for the summer as this practice makes for great games to help kids be involved in activities which are culturally accepted, nurtured and encouraged in daily life. Bingo for young children from kindergarten to senior.\n",
            "\n",
            "According to Keesmiller, and likely to get more traction these days than in past year so it'll also work much like other\n",
            "----\n",
            "For every 100,000 calories consumed, there is $60,000 worth in lost energy. Every 200 seconds, each pound of weight is gained without increasing appetite either for nutrition but for food.\n",
            "\n",
            "We are told that by a large percentage of these energy-hungry folks who think there is simply too most plentiful of vitamins in the human body for them:\n",
            "----\n",
            "Wearing the red and light-reflecting armor, Jyn also held her arm-shield of fire, using that shield's distance for armor-piercing damage up against most dragons. The first time the sword blade slipped from her armor she didn't fully react and she used her shield's power to block off incoming force, much like on Ironborn, forcing her to do that too. She then cast a defensive spell that left her shield on hold long enough for Ironborn to finish the\n",
            "----\n",
            "1.3 * In addition to the functionality found within iOS 6. For more on the best and least demanding use, head on over over to Play Store. 2.9 *** Some things changed *** We are extremely sorry about what's happening to users after one usage this Spring (but nevermind): A bug in The Finder. We will fix the issue to be included in upcoming builds from the team working behind- closed end - iOS support at http://mobilephonesplaycenter.ca/, but it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHkGa3Tv91xz"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "- Remember that the used model is pre-trained. So, it has seen texts that are not Wikipedia articles before and can already formulate sensical text even without training.\n",
        "- When generating text with a prefix that appeared in the training data, the model does not simply repeat the training data (i.e., no overfitting, thanks to using a pretrained model).\n",
        "- Notice that the test loss is going up while the training loss keeps going down (i.e., the model is overfitting). After all, the training set is quite small and is not expected to actually capture what \"wikipedia article\" really means. So, the best model on the *test set* is really the model from epoch 1. Later models (after training for an adequate number of epochs) would be better at producing text that matches the  training set. Still, that would not mean generating generic wikipedia texts.\n",
        "- The impact of *temperature*, *prefix* and *context length* can be seen from the experiments above.\n",
        "- Note that even if training is perfect, this does not guarantee the generated text to be factual. Sounding like Wikipedia and being factual are not the same thing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9vmWB717-9g"
      },
      "source": [
        "3. **(1 point)** Calculate the perplexity of `best_model` on the test set **(0.5 point)**.\n",
        "\n",
        "Generally, a perplexity lower than 30 is desired. Have you been able to achieve it? If not, would you expect more hyper-parameter tuning to solve the issue? Elaborate and reflect on your answers. **(0.5 point)**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1fab8ae3-de6d-46ec-99f8-d0c48b46ba11",
        "id": "EjWg-RES-F7y"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.2700276374816895\n",
            "Perplexity (method 1): 26.312066532474006\n",
            "Perplexity (method 2):  1394.543701171875\n"
          ]
        }
      ],
      "source": [
        "# Since the answer leaves it open, there are multiple ways to calculate the perplexity.\n",
        "\n",
        "# The simplest and easiest way to calculate the perplexity is to exponentiate the loss. Several places provide code for this through a Google search:\n",
        "# https://discuss.huggingface.co/t/guide-the-best-way-to-calculate-the-perplexity-of-fixed-length-models/193/8\n",
        "# https://github.com/huggingface/transformers/blob/0baa9246cb1ddac355db1df7824a521426599eb7/docs/source/en/perplexity.md?plain=1#L122\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(f\"Test Loss: {results['eval_loss']}\")\n",
        "print(f\"Perplexity (method 1): {np.e ** results['eval_loss']}\")\n",
        "\n",
        "\n",
        "# Other more technically complex ways exist. But, since they are iterative in nature, they may provide a difference answer (i.e., different implementations may lead to different numbers):\n",
        "# https://huggingface.co/docs/transformers/perplexity\n",
        "# https://github.com/huggingface/transformers/blob/0baa9246cb1ddac355db1df7824a521426599eb7/docs/source/en/perplexity.md?plain=1#L122\n",
        "\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "\n",
        "def calculate_perplexity(model, test_dataset, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataset:\n",
        "            inputs = torch.tensor(batch['input_ids']).to(device)\n",
        "            targets = torch.tensor(batch['input_ids']).to(device)\n",
        "            mask = torch.tensor(batch['attention_mask']).to(device) if 'attention_mask' in batch else None\n",
        "\n",
        "            outputs = model(inputs, attention_mask=mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Shift the logits and labels to compute loss\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = targets[..., 1:].contiguous()\n",
        "\n",
        "            loss = F.cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            total_count += inputs.size(0)\n",
        "\n",
        "    return torch.exp(torch.tensor(total_loss / total_count)).item()\n",
        "\n",
        "print(\"Perplexity (method 2): \", calculate_perplexity(best_model, test_dataset_tokenized))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki_j2ew-7fsd"
      },
      "source": [
        "4. **(1.5 point)** Now, train a new GPT2. This model `model_from_scratch` is identical to `best_model`, except that it is trained **from scratch**. **(0.5 point)**\n",
        "Once done:\n",
        "\n",
        "  - Calculate the perplexity on the test set. **(0.25 point)**\n",
        "  - Generate some texts. **(0.25 point)**\n",
        "  - Which model is better `best_model` or `model_from_scratch`? Justify and reflect on your answers. **(0.5 point)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3slmHqWNm7A"
      },
      "source": [
        "Create the model and train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "sjCD_uyq3sZF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "0f3c16d8-23d4-4a33-84a5-8d8cbcc06209"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 10:41, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>7.699500</td>\n",
              "      <td>7.806784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.459400</td>\n",
              "      <td>7.660700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>6.138500</td>\n",
              "      <td>7.612943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.893400</td>\n",
              "      <td>7.550513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.671700</td>\n",
              "      <td>7.553468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>5.472800</td>\n",
              "      <td>7.539848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>5.299200</td>\n",
              "      <td>7.539625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>5.157800</td>\n",
              "      <td>7.549890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>5.019400</td>\n",
              "      <td>7.583177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>4.934500</td>\n",
              "      <td>7.580673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=5.774607055664062, metrics={'train_runtime': 641.6236, 'train_samples_per_second': 4.676, 'train_steps_per_second': 2.338, 'total_flos': 783876096000000.0, 'train_loss': 5.774607055664062, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "# IMPORTANT: Initializing a GPT2 configuration from scratch\n",
        "configuration = GPT2Config(\n",
        "    vocab_size=len(tokenizer),  # vocabulary size is the same used in the previous model\n",
        "    n_ctx=context_len, # Setting the same context length.\n",
        ")\n",
        "\n",
        "# Initializing a model (with random weights) from the configuration\n",
        "model = GPT2LMHeadModel(configuration).to(device)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    logging_dir='./from_scratch/logs',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    output_dir=\"./from_scratch/results\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    num_train_epochs=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")\n",
        "\n",
        "trainer2 = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset_tokenized,\n",
        "    eval_dataset=test_dataset_tokenized,\n",
        ")\n",
        "\n",
        "\n",
        "trainer2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "FSYdW3PB42Uh"
      },
      "outputs": [],
      "source": [
        "model_from_scratch = trainer2.model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_name2 = \"/content/drive/MyDrive/IS883_HW2/wiki_from_scratch\"\n",
        "\n",
        "trainer2.save_model(saved_model_name2)\n",
        "model_from_scratch = GPT2LMHeadModel.from_pretrained(saved_model_name2).to(device)"
      ],
      "metadata": {
        "id": "hpkdp0g-UuPE"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfZZqxV0NpBE"
      },
      "source": [
        "Calculate perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "zULyigMaK8Pf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e5cd915a-379e-4fb4-eded-820c9bc2d0ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 7.53962516784668\n",
            "Perplexity (method 1): 1881.124786943412\n",
            "Perplexity (method 2):  99111.6796875\n"
          ]
        }
      ],
      "source": [
        "results = trainer2.evaluate(test_dataset_tokenized)\n",
        "\n",
        "results = trainer2.evaluate()\n",
        "print(f\"Test Loss: {results['eval_loss']}\")\n",
        "print(f\"Perplexity (method 1): {np.e ** results['eval_loss']}\")\n",
        "\n",
        "print(\"Perplexity (method 2): \", calculate_perplexity(model_from_scratch, test_dataset_tokenized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJCfABA0NsS_"
      },
      "source": [
        "Generate Texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_text(model_from_scratch, temperature=1, max_gen_tokens=100, prefix=\"Robert Walpole\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nEcZsHhi7VYN",
        "outputId": "77b6f9d4-d281-4b31-ab4c-f262217b9763"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "Robert Walpole is a part of living in the word in the Kingdom. When people can be a person's world.\n",
            "\n",
            "History \n",
            "\n",
            "\n",
            "|-the people who have always called a number, a computer into two in the same as a type of different, it as a \"to-speaking part of these countries.\n",
            "\n",
            "\n",
            "Ath century\n",
            "The word \"the person's part of the United people have a lot of a planet, a person when a lot of the same as a \"\n",
            "----\n",
            "Robert Walpole is the make of the first. It is a country in the world's is the same day of the planet. It is the other called country in the Latin of the year. It was a one of the country in the same day of the city of the most of a \"which or it was an country to all the other people who have a country in the following by the first day of the world. In the week as the same day of the same day of the week as the same day\n",
            "----\n",
            "Robert Walpole is a kind of the study of people. It is, the language. \n",
            "\n",
            "Ar example, a long time, or a person does not be in other person or any country or group of the person who has the number of many different from the United States. It also be a large people they do not always a.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The island is made of a new area is often called a person, and the or the country or other people say that the English or it a\n",
            "----\n",
            "Robert Walpole is a state of its own country and is the same day of the previous year. It is the previous year.  a country in the world, and on the same day of the week as this of the United States. The first language, the week as the same day of the Sun, which is from the same day of the following year, and the United States.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Related pages\n",
            "\n",
            "In leap years,000 years immediately before common years, they are a common\n",
            "----\n",
            "Robert Walpole is a list of a word. It is the people of a city in the word for it. That in the same as that was part of a new types of the world. It was made of the person's word. It is to \n",
            "\n",
            "In the only one is a type of the body of the language (called a small language.\n",
            "\n",
            "\n",
            "\n",
            "It is one study of the word \"tos, the Greek word \"This language that the human body,000 years, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUQplolNYu21"
      },
      "source": [
        "**Answer:**\n",
        "- Obviously, the fine-tuned model is better based on the loss and perplexity. However, you can also see that the trained-from-scratch model produces non-sensical text. This is because it has little linguistic knowledge as it has never been trained on any text data before, as opposed to the pretrained model that has some linguistic knowledge while we just fine-tuned it on wikipedia text.\n",
        "-  Regardless of which perplexity implementation you have used, the pre-trained model should have yielded a relatively smaller perplexity value than the from-scratch-model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5GtoKeFHw2f"
      },
      "source": [
        "Delete your model and clear `cuda` cache for next experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "QuY811XmOK0r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c34a5eeb-02fe-4781-b910-df6acdbee28b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# While optional, cleaning things up after using them always helps with memory issues\n",
        "\n",
        "del model_from_scratch\n",
        "del best_model\n",
        "del model\n",
        "del wikipedia_simple_dataset\n",
        "del train_dataset\n",
        "del test_dataset\n",
        "\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "b1SPEo1kHwhb"
      },
      "outputs": [],
      "source": [
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUHcTinh5nuA"
      },
      "source": [
        "##**Part 2: Using an language models for translation**\n",
        "\n",
        "Here, you will use an *appropriate* language model of your choice and train it on a dataset that has English-to-French song translations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q9vHUlIu6Dse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87c72f12-0e8a-4c37-ba15-76760b803643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An example row from this dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'artist_name': 'The Beatles',\n",
              " 'album_name': 'Beatles For Sale',\n",
              " 'year': 1964,\n",
              " 'title': 'Rock and Roll Music',\n",
              " 'number': 4,\n",
              " 'original_version': \"chorus\\nJust let me hear some of that rock and roll music\\nAny old way you choose it\\nIt's got a back beat, you can't lose it\\nAny old time you use it\\nIt's gotta be rock and roll music\\nIf you wanna dance with me\\nIf you wanna dance with me\\nI've got no kick against modern jazz\\nUnless they try to play it too darn fast\\nAnd lose the beauty of the melody\\nUntil they sound just like a symphony\\nThat's why I go for that that rock and roll music\\nAny old way you choose it\\nIt's got a back beat, you can't lose it\\nAny old time you use it\\nIt's gotta be rock and roll music\\nIf you wanna dance with me\\nIf you wanna dance with me\\nI took my loved one over across the tracks\\nSo she can hear my man awail a sax\\nI must admit they have a rocking band\\nMan, they were blowing like a hurricane\\nThat's why I go for that that rock and roll music\\nAny old way you choose it\\nIt's got a back beat, you can't lose it\\nAny old time you use it\\nIt's gotta be rock and roll music\\nIf you wanna dance with me\\nIf you wanna dance with me\\nWay down South they had a jubilee\\nThe jokey folks they had a jamboree\\nThey're drinking home brew from a water cup\\nThe folks dancing there are all shook up\\nAnd started playing that that rock and roll music\\nAny old time you use it\\nIt's got a back beat, you can't lose it\\nAny old time you use it\\nIt's gotta be rock and roll music\\nIf you wanna dance with me\\nIf you wanna dance with me\\nDon't care to hear them play a tango\\nAnd In The Mood they take a mambo\\nIt's way to early for a congo\\nSo keep a rocking that piano\",\n",
              " 'french_version': \"Laisse moi juste couter un peu de cette musique rock and roll\\nChoisis-la  l'ancienne\\nIl y a un backbeat, tu ne peux le perdre\\nUtilises-le  l'anciennea sera de la musique rock\\nSi tu veux danser avec moi\\nSi tu veux danser avec moi\\nJe n'ai rien contre la musique jazz\\nTant qu'ils n'essayent pas de la jouer trop rapidement\\nEt perdent la beaut de la mlodie\\nJusqu' ce que a sonne comme une symphonie\\nC'est pour a que je choisis cette musique rock and roll\\nChoisis-la  l'ancienne\\nIl y a un backbeat, tu ne peux le perdre\\nUtilises-le  l'anciennea sera de la musique rock\\nSi tu veux danser avec moi\\nSi tu veux danser avec moi\\nJ'ai emmen ma bien aime sur la piste\\nPour qu'elle puisse entendre le saxophoniste\\nJe dois admettre qu'ils ont un groupe de rock\\nMec, ils dfonaient tout\\nC'est pour a que je choisis cette musique rock and roll\\nChoisis-la  l'ancienne\\nIl y a un backbeat, tu ne peux le perdre\\nUtilises-le  l'anciennea sera de la musique rock\\nSi tu veux danser avec moi\\nSi tu veux danser avec moi\\nEn descendant au Sud ils jubilaient\\nLes jokeys avaient un jamboree\\nIls boivent une mixture maison dans un verre d'eau\\nLa foule qui danse ici est choque\\nEt ils ont commenc  jouer cette musique rock and roll\\nUtilises-la  l'ancienne\\nIl y a un backbeat, tu ne peux le perdre\\nUtilises-le  l'anciennea sera de la musique rock\\nSi tu veux danser avec moi\\nSi tu veux danser avec moi\\nJe me fous de les entendre jouer un tango\\nEt dans l'ambiance ils prennent un mambo\\nIl est beaucoup trop tt pour un congo\\nAlors continue de rocker ce piano\",\n",
              " 'language': 'en'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"Nicolas-BZRD/Original_Songs_Lyrics_with_French_Translation\")\n",
        "\n",
        "# Define a function to check if either 'original_version' or 'french_version' are None\n",
        "def filter_rows(example):\n",
        "    return example['original_version'] is not None and example['french_version'] is not None\n",
        "\n",
        "# Filter the dataset\n",
        "dataset = dataset.filter(filter_rows)\n",
        "\n",
        "print(\"An example row from this dataset\")\n",
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyGkzA4O7A2F"
      },
      "source": [
        "  - Split the dataset into a training set (the first 300 songs) and a test set (the last 60 songs).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TFkxCeoj7HC7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1698207a-920b-4e22-d595-375afbdda928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in training set: 300\n",
            "Number of rows in test set: 60\n"
          ]
        }
      ],
      "source": [
        "# Check the total number of rows in the dataset\n",
        "total_rows = len(dataset[\"train\"])\n",
        "\n",
        "# Ensure the dataset has at least 22k rows\n",
        "if total_rows < 660:\n",
        "    raise ValueError(\"The dataset has fewer than 360 rows.\")\n",
        "\n",
        "# Define the indices for splitting the dataset\n",
        "train_end_idx = 300  # The end index for the training set\n",
        "test_start_idx = total_rows - 60  # The start index for the test set\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_dataset = dataset[\"train\"].select(range(train_end_idx))\n",
        "test_dataset = dataset[\"train\"].select(range(test_start_idx, total_rows))\n",
        "\n",
        "# Print the number of rows in training and test sets\n",
        "print(f\"Number of rows in training set: {len(train_dataset)}\")\n",
        "print(f\"Number of rows in test set: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3a6b7Nab4E9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3c76495f-8b24-4c0a-f421-e37bafc54a79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRLgeakE6n1L"
      },
      "source": [
        "1. **(1.5 point)** Choose a good **pre-trained** model for this task **(0.5 point)**. Explain your criteria for choosing this model. **(0.5 point)** It is highly recommended to select one from [HuggingFace official pre-trained models](https://huggingface.co/docs/transformers/index) or [HuggingFace user pre-trained models](https://huggingface.co/models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUhKjvcGax2b"
      },
      "source": [
        "Create the tokenizer. Use a `max_length` of 512. Remove all columns unnecessary for the translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fgOleSadDBOK"
      },
      "outputs": [],
      "source": [
        "max_length=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vUX7pl9H69CI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "b5f25b2fe16143e9bc398c0438b7cc84",
            "a0066c9799594745985a2d6c2e42fecd",
            "619826909b364f0c8601bd84545959e7",
            "d0c5f69ae7714c92b5a31055d2ef5ee8",
            "cb46604b29234e758606278f802e7229",
            "6e275056d9f14a6093ae3e123cadd092",
            "5d1df1b566b246e39f6fca0af01101cf",
            "8ba12e504a904222af4a5ecd0a457bab",
            "29f36a7acd3f4b5d8112e89f8eb54d60",
            "6172b5162a894b9c9a762290cc00d507",
            "c0e7f64f30c844dcbb5d62de3412a28c",
            "5f1d2d1e827d44808e7a62227d9138e7",
            "77b7b5b77a2a463989ecb891cfbbb3ec",
            "b2b98d7e6662486aa1161b38eb5688e0",
            "6c1be61dd1a24e9ebcbfd3e8920cdba3",
            "09af377e38c54625af900e54c6a57bbb",
            "8a0f35f042c54067bc672fe37599dd88",
            "0614e73fd27343fa992d0da8f2c1bcd4",
            "9bdd408fe9f34e008364990c2aab8816",
            "838f075951c447a6aca21b5cd79cc291",
            "f0964eef429f4f7d9d2b5e2182ba33a7",
            "39539b8f23dd43b6a35390e75fce57d6"
          ]
        },
        "outputId": "18fb9d67-b6d3-49bf-c170-c997d6c13eaf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5f25b2fe16143e9bc398c0438b7cc84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f1d2d1e827d44808e7a62227d9138e7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BartTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import BartConfig, BartForConditionalGeneration\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# Define the tokenizer\n",
        "model_name = 'facebook/bart-base' #Bart, a widely known encoder-decoder model that is suitable for translation.\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_data(example):\n",
        "    input_text = example['original_version']  # Assuming this is the source sequence\n",
        "    target_text = example['french_version']  # Assuming this is the target sequence\n",
        "\n",
        "    # Tokenize the source text (i.e., English)\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        return_tensors='pt',\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True\n",
        "    )\n",
        "\n",
        "    # Tokenize the target text (i.e., French)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        targets = tokenizer(\n",
        "            target_text,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "\n",
        "    # Ensure the attention masks are 2D tensors\n",
        "    inputs['attention_mask'] = inputs['attention_mask'].squeeze()\n",
        "    targets['attention_mask'] = targets['attention_mask'].squeeze()\n",
        "\n",
        "    # Prepare the model inputs\n",
        "    inputs['labels'] = targets['input_ids'].squeeze() # The labels for us are the tokens of the target language (French)\n",
        "    inputs['input_ids'] = inputs['input_ids'].squeeze()\n",
        "\n",
        "    return inputs\n",
        "\n",
        "\n",
        "# Tokenize the datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S7V0A3ji8Fu7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1446836d-1316-480e-a64a-1b641e6f1fdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['artist_name', 'album_name', 'year', 'title', 'number', 'original_version', 'french_version', 'language', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 300\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tokenized_train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xNjzT4ta5qt"
      },
      "source": [
        "Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7eHqT67ta6yN"
      },
      "outputs": [],
      "source": [
        "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh_FtXpxApJH"
      },
      "source": [
        "**Answer:** Here, we chose Bart, an encode-decoder model, because that is best for translation. A decode-only model would have also work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzYcAFQx7pD5"
      },
      "source": [
        "Train the model. **(0.5 point)**\n",
        "\n",
        "  2. **(0.5 point)** You might find that your notebook runs out of memory or takes too long to train. What hyper-parameter could you change to address that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ntPByGA4_M"
      },
      "source": [
        "**Answer:** Generally, the two best ways to gain memory are to\n",
        "- decrease batch size.\n",
        "- choose a smaller model.\n",
        "\n",
        "There are other hyper-parameters that could help, such as [gradient accumulation](https://towardsdatascience.com/what-is-gradient-accumulation-in-deep-learning-ec034122cfa)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_EaMnWYUSVoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "3f3fe32b-b635-45c2-8332-e345367f749c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 11:05, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.008600</td>\n",
              "      <td>2.154631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.806300</td>\n",
              "      <td>2.039860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.644400</td>\n",
              "      <td>1.991508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.532200</td>\n",
              "      <td>1.902242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.431600</td>\n",
              "      <td>1.845371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.351000</td>\n",
              "      <td>1.821475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.297300</td>\n",
              "      <td>1.778309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.249500</td>\n",
              "      <td>1.773595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.211700</td>\n",
              "      <td>1.760024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.194000</td>\n",
              "      <td>1.760480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=1.4726555862426758, metrics={'train_runtime': 666.4027, 'train_samples_per_second': 4.502, 'train_steps_per_second': 0.75, 'total_flos': 914604687360000.0, 'train_loss': 1.4726555862426758, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\n",
        "# Define training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=6,\n",
        "    logging_dir='./translation/logs',\n",
        "    output_dir='./translation/results',\n",
        "    save_total_limit=1,\n",
        "    num_train_epochs=10,\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    predict_with_generate=True,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "\n",
        "# Define trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CtUtzNI5fy17"
      },
      "outputs": [],
      "source": [
        "best_model_q2 = trainer.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUjSUgpT9dRk"
      },
      "source": [
        "3. **(1 point)** Translate the following two sentences **(0.5 point)**. Would your model make a good English-to-French translator? Justify your answer **(0.5 point)**.\n",
        "\n",
        "  - \"Just let me hear some of that rock and roll music\"\n",
        "  - \"If you wanna dance with me\\nI've got no kick against modern jazz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FKJ9VoliEZ5p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def translate_sentence(sentence, model, tokenizer):\n",
        "    # Ensure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input sentence\n",
        "    inputs = tokenizer(\n",
        "        text=sentence,  # Source sequence\n",
        "        return_tensors='pt',  # Return PyTorch tensors\n",
        "        max_length=max_length,  # Max length for the source sequence\n",
        "        truncation=True,  # Truncate the sequence if it's too long\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "    # Move tensors to the same device as the model\n",
        "    inputs = {name: t.to('cuda') for name, t in inputs.items()}\n",
        "\n",
        "    # Generate translation using the model\n",
        "    with torch.no_grad():  # No need to track the gradients\n",
        "        outputs = model.generate(**inputs, max_length=100, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode the generated IDs to get the translated sentence\n",
        "    translated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(sentence, '->', translated_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate_sentence(\"Just let me hear some of that rock and roll music\", best_model_q2, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OEIkkE-RyBld",
        "outputId": "07fa8738-2dc1-4e76-9532-40a9c8931755"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just let me hear some of that rock and roll music -> Just let me hear some of that rock and roll music\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vZp_NXNAHW7p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ed01c623-5607-4efc-f893-c029ffd618e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you wanna dance with me\n",
            "I've got no kick against modern jazz -> Si tu veux dance avec moi\n",
            "Je n'ai jamais quelque chose de modern jazz\n"
          ]
        }
      ],
      "source": [
        "translate_sentence(\"If you wanna dance with me\\nI've got no kick against modern jazz\", best_model_q2, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** It seems the translation is not working fully. Let's train a bit more."
      ],
      "metadata": {
        "id": "6d2PmLMc1Vtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kbLOp1d6ybdY",
        "outputId": "9cdfce7c-3b41-44bc-fbc2-dfda5d73920a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 11:28, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.221100</td>\n",
              "      <td>1.758350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.135900</td>\n",
              "      <td>1.732679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.065000</td>\n",
              "      <td>1.712574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.994800</td>\n",
              "      <td>1.693031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.935700</td>\n",
              "      <td>1.698196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.887600</td>\n",
              "      <td>1.692624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.846200</td>\n",
              "      <td>1.685015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.819000</td>\n",
              "      <td>1.691711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.786600</td>\n",
              "      <td>1.686779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.772600</td>\n",
              "      <td>1.691820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.9464482650756836, metrics={'train_runtime': 689.429, 'train_samples_per_second': 4.351, 'train_steps_per_second': 0.725, 'total_flos': 914604687360000.0, 'train_loss': 0.9464482650756836, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate_sentence(\"Just let me hear some of that rock and roll music\", best_model_q2, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wqnCMPcgy8BV",
        "outputId": "7578e27f-643b-487e-aa56-6221d525794a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Just let me hear some of that rock and roll music -> Juste laissez-moi entendre cette musique rock et roll.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6yQL1K3D2XDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate_sentence(\"If you wanna dance with me\\nI've got no kick against modern jazz\", best_model_q2, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b8rlYzv01iYx",
        "outputId": "1954ea3e-d3ef-4e50-a190-b27c344fd665"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you wanna dance with me\n",
            "I've got no kick against modern jazz -> Si tu veux danser avec moi\n",
            "Je n'ai plus kick de modern jazz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** Looks great. No?! Let's try some other sentences."
      ],
      "metadata": {
        "id": "rlQ93D3T26MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate_sentence(\"Drink some water.\", best_model_q2, tokenizer)\n",
        "translate_sentence(\"Got to work.\", best_model_q2, tokenizer)\n",
        "translate_sentence(\"Sleep early.\", best_model_q2, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tCbuhSp51nvj",
        "outputId": "12da19a0-6fde-4a94-cb6c-8f798ff0def0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drink some water. -> Drink some water.\n",
            "Got to work. -> Got to work.\n",
            "Sleep early. -> Sleep early.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJWYJUStA_aI"
      },
      "source": [
        "**Answer:**\n",
        "- The model translates the first two sentences fairly well (if you check Google translate). However, the model fails translating any other simple sentences.\n",
        "- If we look closely at the first two sentences, they were extracted from the training set (You can actually find them in the example song at the beginning of Q2).\n",
        "- So, our model is not actually good at translation. Rather, it just means it has \"memorized\" the training songs.\n",
        "- The model does not work well with other sentences because it was not pre-trained for translation and has only seen the provided training translations.\n",
        "- However, if the model was pre-trained for translation, then it would give some good translations either way. Though the returned would differ translations from the training lyrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIirjmbSjYOF"
      },
      "source": [
        "4. **(0.5 point)** What would be a good metric for measuring the performance of this model? Could you calculate it for this pair of model and dataset? If yes, show your results and discuss them. If no, elaborate on the reason and how you would go about solving it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lL7c7JhJiO7"
      },
      "source": [
        "**Answer:** One could use metrics such as [BLEU or ROUGE](https://stackoverflow.com/questions/38045290/text-summarization-evaluation-bleu-vs-rouge). However, to use these, you would need *human reference translations* available as part of the dataset, which we do not have here. So, while you could certainly go and generate these translations and calculate the metrics ([See this example](https://huggingface.co/spaces/evaluate-metric/bleu)), it is beyond the scope of this assignment."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5f25b2fe16143e9bc398c0438b7cc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0066c9799594745985a2d6c2e42fecd",
              "IPY_MODEL_619826909b364f0c8601bd84545959e7",
              "IPY_MODEL_d0c5f69ae7714c92b5a31055d2ef5ee8"
            ],
            "layout": "IPY_MODEL_cb46604b29234e758606278f802e7229"
          }
        },
        "a0066c9799594745985a2d6c2e42fecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e275056d9f14a6093ae3e123cadd092",
            "placeholder": "",
            "style": "IPY_MODEL_5d1df1b566b246e39f6fca0af01101cf",
            "value": "Map: 100%"
          }
        },
        "619826909b364f0c8601bd84545959e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba12e504a904222af4a5ecd0a457bab",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29f36a7acd3f4b5d8112e89f8eb54d60",
            "value": 300
          }
        },
        "d0c5f69ae7714c92b5a31055d2ef5ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6172b5162a894b9c9a762290cc00d507",
            "placeholder": "",
            "style": "IPY_MODEL_c0e7f64f30c844dcbb5d62de3412a28c",
            "value": " 300/300 [00:05&lt;00:00, 57.83 examples/s]"
          }
        },
        "cb46604b29234e758606278f802e7229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e275056d9f14a6093ae3e123cadd092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1df1b566b246e39f6fca0af01101cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba12e504a904222af4a5ecd0a457bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f36a7acd3f4b5d8112e89f8eb54d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6172b5162a894b9c9a762290cc00d507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e7f64f30c844dcbb5d62de3412a28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f1d2d1e827d44808e7a62227d9138e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77b7b5b77a2a463989ecb891cfbbb3ec",
              "IPY_MODEL_b2b98d7e6662486aa1161b38eb5688e0",
              "IPY_MODEL_6c1be61dd1a24e9ebcbfd3e8920cdba3"
            ],
            "layout": "IPY_MODEL_09af377e38c54625af900e54c6a57bbb"
          }
        },
        "77b7b5b77a2a463989ecb891cfbbb3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0f35f042c54067bc672fe37599dd88",
            "placeholder": "",
            "style": "IPY_MODEL_0614e73fd27343fa992d0da8f2c1bcd4",
            "value": "Map: 100%"
          }
        },
        "b2b98d7e6662486aa1161b38eb5688e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bdd408fe9f34e008364990c2aab8816",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_838f075951c447a6aca21b5cd79cc291",
            "value": 60
          }
        },
        "6c1be61dd1a24e9ebcbfd3e8920cdba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0964eef429f4f7d9d2b5e2182ba33a7",
            "placeholder": "",
            "style": "IPY_MODEL_39539b8f23dd43b6a35390e75fce57d6",
            "value": " 60/60 [00:00&lt;00:00, 72.64 examples/s]"
          }
        },
        "09af377e38c54625af900e54c6a57bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a0f35f042c54067bc672fe37599dd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0614e73fd27343fa992d0da8f2c1bcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bdd408fe9f34e008364990c2aab8816": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838f075951c447a6aca21b5cd79cc291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0964eef429f4f7d9d2b5e2182ba33a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39539b8f23dd43b6a35390e75fce57d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}