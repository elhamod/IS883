{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4FDekTFJuaW"
      },
      "source": [
        "# IS883 Week4: Using OpenAI API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7KF7bFqKEIG"
      },
      "source": [
        "1. Use Google Colab for this assignment.\n",
        "\n",
        "2. **You are NOT allowed to use ChatGPT for this assignment. However, you may use Google and other online resources. As per the syllabus, you are required to cite your usage. You are also responsible for understanding the solution and defending it when asked in class.**\n",
        "\n",
        "3. For each question, fill in the answer in the cell(s) right below it. The answer could be code or text. You can add as many cells as you need for clarity.\n",
        "\n",
        "4. Enter your BUID (only numerical part) below.\n",
        "\n",
        "5. **Your submission on Blackboard should be the downloaded notebook (i.e., ipynb file). It should be prepopulated with your solution (i.e., the TA and/or instructor need not rerun the notebook to inspect the output). The code, when executed by the TA and/or instructor, should run with no runtime errors.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F95dcB4zKOnw"
      },
      "source": [
        "#Part 1: Pre-class Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ic8VY0SNXX5"
      },
      "source": [
        "## 1.1 Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QxJrXiOXgP5"
      },
      "source": [
        "Install some important HuggingFace packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL8sYzUuXpR8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UdoGs8-UeOab"
      },
      "outputs": [],
      "source": [
        "BUID = 123456 #e.g., 123456 ONLY NUMERICAL PART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ssLsZbOeOac"
      },
      "source": [
        " Machine learning is generally stochastic, meaning you get different results for different runs. To avoid that, you can \"seed\" your code. This code uses your BU id (only the numeric part) as a seed for all random number generators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c3djGT1QeOac"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import set_seed\n",
        "\n",
        "# Set a seed for the built-in Python random module\n",
        "random.seed(BUID)\n",
        "# Set a seed for NumPy\n",
        "np.random.seed(BUID)\n",
        "# Set a seed for HuggingFace\n",
        "set_seed(BUID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4sXkvRTLxUA"
      },
      "source": [
        "##1.2 Using OpenAI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9HbjkFH0McU"
      },
      "source": [
        "###1.2.1 Install OpenAI package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKLoIDLh0XYq",
        "outputId": "d3489399-1bcc-40f6-ae47-9540f57b0418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.47.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ckx72mp0RQc"
      },
      "source": [
        "###1.2.2 Generate Text with OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzx2LL7LszE"
      },
      "source": [
        "Now that you have already experimented with loading a language model (GPT2) *locally* and using it to generate some sentences last week, how about we instead use someone else's model through an API? Let's experiment with OpenAI's API!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjSt3_mBrohm"
      },
      "source": [
        "- In order to use OpenAI API, you first need to get an API key that allows you to use the class's OpenAI resources. You can create the key through [this link](https://platform.openai.com/api-keys) after signing in.\n",
        "- Once you have created the key, you will save it as a secret in Google Colab. See [this example](https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0) for how to store and load the API key. For grading purposes, you MUST name your key *MyOpenAIKey*.\n",
        "- Now, you are set! Use [OpenAI API documentation](https://platform.openai.com/docs/guides/text-generation) to complete the same two prefixes in 1.2.2. [This webpag](https://platform.openai.com/docs/api-reference/chat/create)e may also be helpful. **(10 Points)**\n",
        "  - You must use the *gpt-4o-mini* model.\n",
        "  - You will generate up to 20 tokens per request.\n",
        "  - You will generate 10 different completions.\n",
        "  - You will set the seed to be your BUID.\n",
        "  - Make sure the API call *completes* the given prefix (i.e., it does not start a new sentence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1JSEA03Jb9M"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "### Load your API Key\n",
        "\n",
        "\n",
        "### Request the answer to the question \"Damascus is a\"\n",
        "\n",
        "\n",
        "### Print all 10 completions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aPZ5GDVz3Nj"
      },
      "outputs": [],
      "source": [
        "### Request the answer to the question \"Barcelona is a\"\n",
        "\n",
        "\n",
        "### Print all 10 completions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3tuOvFaIZHO"
      },
      "source": [
        "### 1.2.3 Reflective Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQpqlQcPIUT9"
      },
      "source": [
        "1. What do you notice about the generated texts for the two prompts? Any interesting commonalities or stark differences? **(5 Points)**\n",
        "\n",
        "2. How do the results in 1.2.2 compared to those from 1.2.1 from Week 3 Pre Class (using GPT2)? What do you think is the underlying cause? **(5 Points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loVq9xh4mOpn"
      },
      "source": [
        "**Answers**\n",
        "\n",
        "Type your Answers here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Z4FDekTFJuaW",
        "F95dcB4zKOnw",
        "_ic8VY0SNXX5",
        "P4sXkvRTLxUA",
        "M9HbjkFH0McU",
        "5ckx72mp0RQc",
        "t3tuOvFaIZHO"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}