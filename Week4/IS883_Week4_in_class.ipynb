{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/IS883/blob/main/Week4/IS883_Week4_in_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4FDekTFJuaW"
      },
      "source": [
        "# IS883 Week4: Using OpenAI API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7KF7bFqKEIG"
      },
      "source": [
        "1. Use Google Colab for this assignment.\n",
        "\n",
        "2. **You are NOT allowed to use ChatGPT for this assignment. However, you may use Google and other online resources. As per the syllabus, you are required to cite your usage. You are also responsible for understanding the solution and defending it when asked in class.**\n",
        "\n",
        "3. For each question, fill in the answer in the cell(s) right below it. The answer could be code or text. You can add as many cells as you need for clarity.\n",
        "\n",
        "4. Enter your BUID (only numerical part) below.\n",
        "\n",
        "5. **Your submission on Blackboard should be the downloaded notebook (i.e., ipynb file). It should be prepopulated with your solution (i.e., the TA and/or instructor need not rerun the notebook to inspect the output). The code, when executed by the TA and/or instructor, should run with no runtime errors.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F95dcB4zKOnw"
      },
      "source": [
        "#Part 1: Pre-class Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ic8VY0SNXX5"
      },
      "source": [
        "## 1.1 Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QxJrXiOXgP5"
      },
      "source": [
        "Install some important HuggingFace packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL8sYzUuXpR8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdoGs8-UeOab"
      },
      "outputs": [],
      "source": [
        "BUID = 123456 #e.g., 123456 ONLY NUMERICAL PART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ssLsZbOeOac"
      },
      "source": [
        " Machine learning is generally stochastic, meaning you get different results for different runs. To avoid that, you can \"seed\" your code. This code uses your BU id (only the numeric part) as a seed for all random number generators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3djGT1QeOac"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import set_seed\n",
        "\n",
        "# Set a seed for the built-in Python random module\n",
        "random.seed(BUID)\n",
        "# Set a seed for NumPy\n",
        "np.random.seed(BUID)\n",
        "# Set a seed for HuggingFace\n",
        "set_seed(BUID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4sXkvRTLxUA"
      },
      "source": [
        "##1.2 Using OpenAI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9HbjkFH0McU"
      },
      "source": [
        "###1.2.1 Install OpenAI package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKLoIDLh0XYq"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ckx72mp0RQc"
      },
      "source": [
        "###1.2.2 Generate Text with OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzx2LL7LszE"
      },
      "source": [
        "Now that you have already experimented with loading a language model (GPT2) *locally* and using it to generate some sentences last week, how about we instead use someone else's model through an API? Let's experiment with OpenAI's API!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjSt3_mBrohm"
      },
      "source": [
        "- In order to use OpenAI API, you first need to get an API key that allows you to use the class's OpenAI resources. You can create the key through [this link](https://platform.openai.com/api-keys) after signing in.\n",
        "- Once you have created the key, you will save it as a secret in Google Colab. See [this example](https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0) for how to store and load the API key. For grading purposes, you MUST name your key *MyOpenAIKey*.\n",
        "- Now, you are set! Use [OpenAI API documentation](https://platform.openai.com/docs/guides/text-generation) to complete the same two prefixes in 1.2.2. [This webpag](https://platform.openai.com/docs/api-reference/chat/create)e may also be helpful. **(10 Points)**\n",
        "  - You must use the *gpt-4o-mini* model.\n",
        "  - You will generate up to 20 tokens per request.\n",
        "  - You will generate 10 different completions.\n",
        "  - You will set the seed to be your BUID.\n",
        "  - Make sure the API call *completes* the given prefix (i.e., it does not start a new sentence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1JSEA03Jb9M"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "### Load your API Key\n",
        "\n",
        "\n",
        "### Request the answer to the question \"Damascus is a\"\n",
        "\n",
        "\n",
        "### Print all 10 completions:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aPZ5GDVz3Nj"
      },
      "outputs": [],
      "source": [
        "### Request the answer to the question \"Barcelona is a\"\n",
        "\n",
        "\n",
        "### Print all 10 completions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3tuOvFaIZHO"
      },
      "source": [
        "### 1.2.3 Reflective Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQpqlQcPIUT9"
      },
      "source": [
        "1. What do you notice about the generated texts for the two prompts? Any interesting commonalities or stark differences? **(5 Points)**\n",
        "\n",
        "2. How do the results in 1.2.2 compared to those from 1.2.1 from Week 3 Pre Class (using GPT2)? What do you think is the underlying cause? **(5 Points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loVq9xh4mOpn"
      },
      "source": [
        "**Answers**\n",
        "\n",
        "Type your Answers here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: In-class Work"
      ],
      "metadata": {
        "id": "jg7CUF5DKE_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 OpenAI API's parameters"
      ],
      "metadata": {
        "id": "7XcElKZW81h8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that temperature controls the *predictibility* of the generated text. Whe temperature is high, the generated text becomes more diverse and interesting but less coherenct/predictable. The opposite is also true.\n",
        "\n",
        "Let's for example try to generate some lyrics about a dad's love for his baby daughter. Let's generate 10 sentences to be able to assess the predictability of the model."
      ],
      "metadata": {
        "id": "-om_dE0V9xhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables to adjust\n",
        "# temperature = 1\n",
        "# max_completion_tokens=25\n",
        "# stop=\".\"\n",
        "\n",
        "\n",
        "### Request the answer to the question \"Damascus is a\"\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an experienced lyricist\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a short poem of 5 lines about a dad's love for his baby daughter.\"}\n",
        "  ],\n",
        "  seed = BUID,\n",
        "  n=10,\n",
        ")\n",
        "\n",
        "### Print all 10 completions:\n",
        "for i in range(10):\n",
        "  print(\"verse\", i, \":\", response.choices[i].message.content)\n",
        "  print(\"-----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mN1PqWV-mgR",
        "outputId": "1d6c8e8d-c128-4ddc-dffc-53a31f0b1157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verse 0 : In gentle whispers, dreams take flight,  \n",
            "A father's heart radiates pure light.  \n",
            "With tiny fingers wrapped around his own,  \n",
            "In her laughter, he finds his home.  \n",
            "A bond unbreakable, forever bright.  \n",
            "-----------\n",
            "verse 1 : In gentle whispers, love's embrace,  \n",
            "A tiny hand, a sacred space.  \n",
            "With every laugh, a joy takes flight,  \n",
            "A father's heart, in pure delight.  \n",
            "In her sweet gaze, the stars ignite.\n",
            "-----------\n",
            "verse 2 : In gentle arms, a world anew,  \n",
            "Soft whispers dance, the night’s deep blue,  \n",
            "Her laughter rings like morning light,  \n",
            "With every step, he feels so right,  \n",
            "A father’s heart, forever true.\n",
            "-----------\n",
            "verse 3 : In gentle whispers, dreams take flight,  \n",
            "A father's heart, a guiding light.  \n",
            "With every giggle, joy unfurls,  \n",
            "He holds the world in tiny curls.  \n",
            "In his embrace, love's lullaby swirls.  \n",
            "-----------\n",
            "verse 4 : In gentle arms, the world stands still,  \n",
            "A soft embrace, a heart to fill.  \n",
            "With every laugh, a star is born,  \n",
            "In silent nights, his dreams adorn.  \n",
            "A father’s love, pure and bright as dawn.  \n",
            "-----------\n",
            "verse 5 : In gentle arms, a world unfolds,  \n",
            "Soft whispers shared like secrets told.  \n",
            "Her laughter dances, pure and bright,  \n",
            "He guards her dreams through day and night.  \n",
            "A bond unbreakable, a love that grows.\n",
            "-----------\n",
            "verse 6 : In gentle arms, a world begins,  \n",
            "His heartbeat whispers, love within,  \n",
            "Her laughter sparkles, pure and bright,  \n",
            "A guiding star in soft moonlight,  \n",
            "Together, they dance, heartstrings entwined.\n",
            "-----------\n",
            "verse 7 : In gentle arms, a soft embrace,  \n",
            "A world of dreams in her small space.  \n",
            "His laughter dances, her giggles soar,  \n",
            "A bond unbroken, forevermore.  \n",
            "In her bright eyes, he finds his grace.\n",
            "-----------\n",
            "verse 8 : In gentle whispers, dreams take flight,  \n",
            "His arms a fortress, strong through the night.  \n",
            "With every giggle, his heart takes wing,  \n",
            "A world of wonder in her laughter’s ring.  \n",
            "In her small hand, he finds his light.\n",
            "-----------\n",
            "verse 9 : In gentle arms, a treasure lies,  \n",
            "With sparkling gaze that lights the skies.  \n",
            "Each giggle fills the air with grace,  \n",
            "A heart's embrace, a warm embrace.  \n",
            "In every step, love's dance unfolds, a story cherished, yet untold.  \n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.4.2 Reflective Questions"
      ],
      "metadata": {
        "id": "nCzM7Kuf0xq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the possible parameters you could play with [here](https://platform.openai.com/docs/api-reference/chat/create?lang=python). Experiment with the following changes:\n",
        "\n",
        "1.   Limit the length of generated poem to 25 tokens.\n",
        "2.   Try a different model and see which poem is more to your liking.\n",
        "\n"
      ],
      "metadata": {
        "id": "e8RlzHLm0172"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Z4FDekTFJuaW",
        "F95dcB4zKOnw",
        "_ic8VY0SNXX5",
        "P4sXkvRTLxUA",
        "M9HbjkFH0McU",
        "5ckx72mp0RQc",
        "t3tuOvFaIZHO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}