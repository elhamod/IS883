{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/IS883/blob/main/Week4/IS883_Week4_in_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4FDekTFJuaW"
      },
      "source": [
        "# IS883 Week4: Using OpenAI API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7KF7bFqKEIG"
      },
      "source": [
        "1. Use Google Colab for this assignment.\n",
        "\n",
        "2. **You are NOT allowed to use ChatGPT for this assignment. However, you may use Google and other online resources. As per the syllabus, you are required to cite your usage. You are also responsible for understanding the solution and defending it when asked in class.**\n",
        "\n",
        "3. For each question, fill in the answer in the cell(s) right below it. The answer could be code or text. You can add as many cells as you need for clarity.\n",
        "\n",
        "4. Enter your BUID (only numerical part) below.\n",
        "\n",
        "5. **Your submission on Blackboard should be the downloaded notebook (i.e., ipynb file). It should be prepopulated with your solution (i.e., the TA and/or instructor need not rerun the notebook to inspect the output). The code, when executed by the TA and/or instructor, should run with no runtime errors.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F95dcB4zKOnw"
      },
      "source": [
        "#Part 1: Pre-class Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ic8VY0SNXX5"
      },
      "source": [
        "## 1.1 Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QxJrXiOXgP5"
      },
      "source": [
        "Install some important HuggingFace packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UdoGs8-UeOab"
      },
      "outputs": [],
      "source": [
        "BUID = 123456 #e.g., 123456 ONLY NUMERICAL PART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ssLsZbOeOac"
      },
      "source": [
        " Machine learning is generally stochastic, meaning you get different results for different runs. To avoid that, you can \"seed\" your code. This code uses your BU id (only the numeric part) as a seed for all random number generators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "c3djGT1QeOac"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import set_seed\n",
        "\n",
        "# Set a seed for the built-in Python random module\n",
        "random.seed(BUID)\n",
        "# Set a seed for NumPy\n",
        "np.random.seed(BUID)\n",
        "# Set a seed for HuggingFace\n",
        "set_seed(BUID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4sXkvRTLxUA"
      },
      "source": [
        "##1.2 Using OpenAI API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9HbjkFH0McU"
      },
      "source": [
        "###1.2.1 Install OpenAI package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UKLoIDLh0XYq",
        "outputId": "961f888c-a6f5-4f0b-b9b6-255385a1b99b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.51.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ckx72mp0RQc"
      },
      "source": [
        "###1.2.2 Generate Text with OpenAI API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzx2LL7LszE"
      },
      "source": [
        "Now that you have already experimented with loading a language model (GPT2) *locally* and using it to generate some sentences last week, how about we instead use someone else's model through an API? Let's experiment with OpenAI's API!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjSt3_mBrohm"
      },
      "source": [
        "- In order to use OpenAI API, you first need to get an API key that allows you to use the class's OpenAI resources. You can create the key through [this link](https://platform.openai.com/api-keys) after signing in.\n",
        "- Once you have created the key, you will save it as a secret in Google Colab. See [this example](https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0) for how to store and load the API key. For grading purposes, you MUST name your key *MyOpenAIKey*.\n",
        "- Now, you are set! Use [OpenAI API documentation](https://platform.openai.com/docs/guides/text-generation) to complete the same two prefixes in 1.2.2. [This webpag](https://platform.openai.com/docs/api-reference/chat/create)e may also be helpful. **(10 Points)**\n",
        "  - You must use the *gpt-4o-mini* model.\n",
        "  - You will generate up to 20 tokens per request.\n",
        "  - You will generate 10 different completions.\n",
        "  - You will set the seed to be your BUID.\n",
        "  - Make sure the API call *completes* the given prefix (i.e., it does not start a new sentence)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "z1JSEA03Jb9M",
        "outputId": "68a6d1e3-f65a-4275-8305-4102aa04ce73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Damascus is a city in Syria and is one of the oldest continuously inhabited cities in the world.\n",
            "Damascus is a city in Syria that is known for its rich history and cultural significance. It is\n",
            "historical city located in Syria, known for its rich cultural heritage and ancient history. It is often\n",
            "city in Syria, known for its rich history and cultural significance. It is one of the oldest continuously\n",
            "Damascus is a city in Syria, known for its rich history and cultural significance. It is one\n",
            "Damascus is a city in Syria, known for its rich history and cultural significance. It is one\n",
            "Damascus is a city in Syria, known for its rich history and cultural significance. It is one\n",
            "Damascus is a city in Syria, known for its rich history and cultural significance. It is one\n",
            "Damascus is a city in Syria, known for its rich history and cultural significance. It is one\n",
            "Damascus is a city in Syria, often regarded as one of the oldest continuously inhabited cities in the\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "### Load your API Key\n",
        "my_secret_key = userdata.get('MyOpenAIKey')\n",
        "os.environ[\"OPENAI_API_KEY\"] = my_secret_key\n",
        "\n",
        "\n",
        "### Request the answer to the question \"Damascus is a\"\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Complete the following prefix\"},\n",
        "    {\"role\": \"user\", \"content\": \"Damascus is a\"}\n",
        "  ],\n",
        "  seed = BUID,\n",
        "  n=10,\n",
        "  max_tokens=20\n",
        ")\n",
        "\n",
        "### Print all 10 completions:\n",
        "for i in range(10):\n",
        "  print(response.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5aPZ5GDVz3Nj",
        "outputId": "a453b08e-8e1b-4b48-ca09-6fedb0d3fc49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Barcelona is a vibrant city located in northeastern Spain, known for its rich history, stunning architecture, and\n",
            "Barcelona is a vibrant city located in Spain, known for its rich history, stunning architecture, and lively\n",
            "Barcelona is a vibrant city located on the northeastern coast of Spain, known for its rich history, stunning\n",
            "Barcelona is a vibrant city located in the northeastern part of Spain, known for its rich history, stunning\n",
            "Barcelona is a vibrant city located in northeastern Spain, known for its rich history, stunning architecture, and\n",
            "Barcelona is a vibrant city located on the northeast coast of Spain, along the Mediterranean Sea. It is\n",
            "Barcelona is a vibrant city located in northeastern Spain, known for its rich history, stunning architecture, and\n",
            "Barcelona is a vibrant city located in northeastern Spain, known for its unique architecture, rich history, and\n",
            "Barcelona is a vibrant city located in northeastern Spain, known for its rich history, stunning architecture, and\n",
            "Barcelona is a vibrant city located in northeastern Spain, known for its unique blend of modern and historical architecture\n"
          ]
        }
      ],
      "source": [
        "### Request the answer to the question \"Barcelona is a\"\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Complete the following prefix\"},\n",
        "    {\"role\": \"user\", \"content\": \"Barcelona is a\"}\n",
        "  ],\n",
        "  seed = BUID,\n",
        "  n=10,\n",
        "  max_tokens=20\n",
        ")\n",
        "\n",
        "### Print all 10 completions:\n",
        "for i in range(10):\n",
        "  print(response.choices[i].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3tuOvFaIZHO"
      },
      "source": [
        "### 1.2.3 Reflective Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQpqlQcPIUT9"
      },
      "source": [
        "1. What do you notice about the generated texts for the two prompts? Any interesting commonalities or stark differences? **(5 Points)**\n",
        "\n",
        "2. How do the results in 1.2.2 compared to those from 1.2.1 from Week 3 Pre Class (using GPT2)? What do you think is the underlying cause? **(5 Points)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loVq9xh4mOpn"
      },
      "source": [
        "**Answers**\n",
        "\n",
        "1. The generated texts here seem a lot less negatively biased and more coherent.\n",
        "2. The OpenAI API responses are way better than those of the pre-trained GPT2. This indicates that the OpenAI API model (i.e. GPT4) is more complex but ALSO has been exposes to much richer data and/or has been trained more properly."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: In-class Work"
      ],
      "metadata": {
        "id": "jg7CUF5DKE_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 OpenAI API's parameters"
      ],
      "metadata": {
        "id": "7XcElKZW81h8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that temperature controls the *predictibility* of the generated text. Whe temperature is high, the generated text becomes more diverse and interesting but less coherenct/predictable. The opposite is also true.\n",
        "\n",
        "Let's for example try to generate some lyrics about a dad's love for his baby daughter. Let's generate 10 sentences to be able to assess the predictability of the model."
      ],
      "metadata": {
        "id": "-om_dE0V9xhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables to adjust\n",
        "temperature = 1.7\n",
        "# max_completion_tokens=25\n",
        "# stop=\".\"\n",
        "\n",
        "\n",
        "### Request the answer to the question \"Damascus is a\"\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an experienced lyricist\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a short poem of 5 lines about a dad's love for his baby daughter.\"}\n",
        "  ],\n",
        "  seed = BUID,\n",
        "  n=10,\n",
        "  temperature = 1,\n",
        "  # max_completion_tokens=25,\n",
        "  # stop=\".\"\n",
        ")\n",
        "\n",
        "### Print all 10 completions:\n",
        "for i in range(10):\n",
        "  print(\"verse\", i, \":\", response.choices[i].message.content)\n",
        "  print(\"-----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mN1PqWV-mgR",
        "outputId": "a8af55a7-0fe1-4e58-c82d-1b80233d01a8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verse 0 : In gentle whispers, dreams take flight,  \n",
            "A father's heart radiates pure light.  \n",
            "With tiny fingers wrapped around his own,  \n",
            "In her laughter, he finds his home.  \n",
            "A bond unbreakable, forever bright.  \n",
            "-----------\n",
            "verse 1 : In gentle whispers, love's embrace,  \n",
            "A tiny hand, a sacred space.  \n",
            "With every laugh, a joy takes flight,  \n",
            "A father's heart, in pure delight.  \n",
            "In her sweet gaze, the stars ignite.\n",
            "-----------\n",
            "verse 2 : In gentle arms, a world anew,  \n",
            "Soft whispers dance, the night’s deep blue,  \n",
            "Her laughter rings like morning light,  \n",
            "With every step, he feels so right,  \n",
            "A father’s heart, forever true.\n",
            "-----------\n",
            "verse 3 : In gentle whispers, dreams take flight,  \n",
            "A father's heart, a guiding light.  \n",
            "With every giggle, joy unfurls,  \n",
            "He holds the world in tiny curls.  \n",
            "In his embrace, love's lullaby swirls.  \n",
            "-----------\n",
            "verse 4 : In gentle arms, the world stands still,  \n",
            "A soft embrace, a heart to fill.  \n",
            "With every laugh, a star is born,  \n",
            "In silent nights, his dreams adorn.  \n",
            "A father’s love, forever bright, a guiding light.  \n",
            "-----------\n",
            "verse 5 : In gentle arms, a world unfolds,  \n",
            "Soft whispers shared like secrets told.  \n",
            "Her laughter dances, pure and bright,  \n",
            "He guards her dreams through day and night.  \n",
            "A bond unbreakable, a love that grows.\n",
            "-----------\n",
            "verse 6 : In gentle arms, a world begins,  \n",
            "His heartbeat whispers, love within,  \n",
            "Her laughter dances, sparkles bright,  \n",
            "A father's pride, a guiding light,  \n",
            "In every hug, a dream takes flight.\n",
            "-----------\n",
            "verse 7 : In gentle arms, a soft embrace,  \n",
            "A world of dreams in her small space.  \n",
            "His laughter dances, her eyes ignite,  \n",
            "In every heartbeat, his love takes flight.  \n",
            "A bond unbroken, shining bright.  \n",
            "-----------\n",
            "verse 8 : In gentle whispers, dreams take flight,  \n",
            "His arms a fortress, strong through the night.  \n",
            "With every giggle, his heart takes wing,  \n",
            "A world of wonder in her laughter’s ring.  \n",
            "In her small hand, he finds his light.\n",
            "-----------\n",
            "verse 9 : In gentle arms, a treasure lies,  \n",
            "With sparkling gaze that lights the skies.  \n",
            "Each giggle fills the air with grace,  \n",
            "A heart's embrace, a warm embrace.  \n",
            "In every step, love's dance unfolds, a story cherished, yet untold.  \n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.4.2 Reflective Questions"
      ],
      "metadata": {
        "id": "nCzM7Kuf0xq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the possible parameters you could play with [here](https://platform.openai.com/docs/api-reference/chat/create?lang=python). Experiment with the following changes:\n",
        "\n",
        "1.   Limit the length of generated poem to 25 tokens.\n",
        "2.   Try a different model and see which poem is more to your liking.\n",
        "\n"
      ],
      "metadata": {
        "id": "e8RlzHLm0172"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Z4FDekTFJuaW",
        "F95dcB4zKOnw",
        "_ic8VY0SNXX5",
        "P4sXkvRTLxUA",
        "M9HbjkFH0McU",
        "5ckx72mp0RQc",
        "t3tuOvFaIZHO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}