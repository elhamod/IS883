{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1In_5dFR_1WRI2w-qfk0kHXIVUvIjjulv",
      "authorship_tag": "ABX9TyMLJZIyww44dj//Y+c3Ly9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/IS883/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using `LangChain` for Prompt Engineering"
      ],
      "metadata": {
        "id": "KyX90VY4i7Y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q0: Loading OpenAI API key"
      ],
      "metadata": {
        "id": "JPkbs259XQ9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "id": "CR52h7TlXX5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "0wLnzuBTXZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_ini_location = '/content/drive/MyDrive/Colab Notebooks/IS883/OpenAI guide/config.ini' # Change this to point to the location of your config.ini file.\n",
        "\n",
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(config_ini_location)\n",
        "openai_api_key = config['OpenAI']['API_KEY']"
      ],
      "metadata": {
        "id": "sEUeXLsOXb2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1: FiniBot, financial advising simplified!"
      ],
      "metadata": {
        "id": "6QOIueVJiup4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have seen in class, breaking a prompt down into chains is useful and, if engineered well, returns better and more reliably responses.\n",
        "\n",
        "[In class](https://github.com/elhamod/IS883/blob/main/Prompt_Engineering_Agents.ipynb), we have seen the most basic form of chains, a `SequentialChain`. However, other more sophisticated chains exist. Here, you will explore a [`RouterChain`](https://python.langchain.com/docs/modules/chains/foundational/router#legacy-routerchain). This chain acts like a switch. Given a condition, it decided which prompt to use. This is in contrast to the deterministic sequantial nature of `SequentialChain`.\n",
        "\n",
        "Using `RouterChain`, and in a manner similar to [`LangChain` in-class demo](https://github.com/elhamod/IS883/blob/main/Prompt_Engineering_Agents.ipynb), write a solution for the following scenario:\n",
        "\n",
        "-----------------------------------\n",
        "You are creating a financial advising ChatBot, FiniBot. Yor clients will fill out [the following csv file](https://docs.google.com/spreadsheets/d/1wJHJE7hrXcedpk9bTQ0oulwTTs41wu32TPTw0FebwXw/edit?usp=sharing), which contains a cell for savings, another for monthly debt, and finally a cell for monthly income. You ChatBot will\n",
        " 1. Download the file as an `.csv` to your Google Drive.\n",
        " 2. Load the file to the notebook.\n",
        " 3. Based on the content of the file, describe your client's situation objectively and in one of two levels: \"Novice\" and \"Expert\".\n",
        " 4. Based on the client's situation:\n",
        " - If your client's [debt ratio](https://www.investopedia.com/ask/answers/081214/whats-considered-be-good-debttoincome-dti-ratio.asp#:~:text=Lenders%2C%20including%20anyone%20who%20might,lenders%20prefer%2036%25%20or%20below.) is less than 0.3, then FiniBot will commend the client's financial accomplishment and then turn into an investment advisor. It will advise to invest their money and provide them with an investment portfolio based on their savings and using 5 stocks.\n",
        " - Otherwise, FiniBot will politely and cautiously, without taking them on a guilt trip, warn the client about their financial situation. It will then turn into a debt advisor, and create a plan for them to pay off their debt by allocating 10% of their income for monthly debt payments.\n",
        "---------------------------------------\n",
        "\n",
        "The final output of your code should be (as text):\n",
        "---------------------------\n",
        "<pre>\n",
        " - Total savings:  < value >\n",
        " - Monthly debt: < value >\n",
        " - Monthly income: < value >\n",
        "\n",
        " - Financial situation:\n",
        " < Your ChatBots Financial summary in \"Novice\" or \"Expert\" tone >\n",
        "\n",
        "- Recommendation:\n",
        " < Your advisor's output >\n",
        " </pre>\n",
        "-----------------\n"
      ],
      "metadata": {
        "id": "xfJfAyrYGKl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "yH7YpTeN11Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load the `.csv` file as text. You can use [`CSVLoader`](https://python.langchain.com/docs/integrations/document_loaders/csv)"
      ],
      "metadata": {
        "id": "EKXYtaSG0zd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IS883/IS883_Assignment3_FiniBot.csv\""
      ],
      "metadata": {
        "id": "hA-HDbuz1lKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadCSVFile(csv_path):\n",
        "######\n",
        "# Fill in your implementation here to return the csv file content as plain text.\n",
        "#######\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "mB25dkVQ0zBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the content of the file\n",
        "text = loadCSVFile(csv_path)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "NlzsUGrM18sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, define `Output_template`, the text that contains the formatted output message as described above. This template has `{input}` as input string. Assume that `{input}` contains the final variables of interest: the input savings, debt, income, and output summary."
      ],
      "metadata": {
        "id": "4hqcNOZ04ib-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Output_template=\"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EMqMRV1xPhBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here define the `investmet_template`, which should act as the prompt template used when the investment advisor is selected. This template has {input} as input string. Assume that {input} contains the final variables of interest: the input savings, debt, income, and output summary."
      ],
      "metadata": {
        "id": "DMYa7lnK5Z39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "investmet_template =\"\"\"\n",
        "\n",
        "\"\"\" + Output_template"
      ],
      "metadata": {
        "id": "dkYmYMai7peB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here define the `debt_template`, which should act as the prompt template used when the debt advisor is selected. This template has {input} as input string. Assume that {input} contains the final variables of interest: the input savings, debt, income, and output summary."
      ],
      "metadata": {
        "id": "5YBkOfSC5oM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debt_template= \"\"\"\n",
        "\n",
        "\"\"\" + Output_template"
      ],
      "metadata": {
        "id": "oiCWTmcP7pgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, define the two possible routes that can be taken as described above. Follow the example shown [here](https://python.langchain.com/docs/modules/chains/foundational/router#legacy-routerchain).\n",
        "Each branch should define the **name** of the route, its **description** (which will be used to select the route), and the **template** that will be used for that route."
      ],
      "metadata": {
        "id": "i6toJclF5yRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "routes ="
      ],
      "metadata": {
        "id": "RlBufkow7FqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, define the variable that sets the `level` of the returned summary."
      ],
      "metadata": {
        "id": "RHIIf-Kk6dOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "level= \"Novice\" #\"Expert\""
      ],
      "metadata": {
        "id": "5_9rB2bvAj4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the `langchain.llms.OpenAI` language model. name it `llm`. As you progress with your assignment, consider what appropriate [parameters](https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html) to use here."
      ],
      "metadata": {
        "id": "iyE2feLR_0tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm ="
      ],
      "metadata": {
        "id": "ce6eVHkI_3bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "m5a-eSA59dTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a destination chain for each possible route. Follow the example shown [here](https://python.langchain.com/docs/modules/chains/foundational/router#legacy-routerchain)."
      ],
      "metadata": {
        "id": "AEZ6Qikm_vsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "destination_chains ="
      ],
      "metadata": {
        "id": "jarl4g5r_XpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a `financial_prompt` for summarizing the client's situation. Include the client's financial knowledge `{level}` as a parameter in this template.\n",
        "- Make sure to use the prompt engineering tips we used in class. You may find [these tips](https://pbs.twimg.com/media/F0RWXIjXgAARNAG?format=jpg&name=4096x4096) useful.\n",
        "- Make sure your prompt is talking the client as a chatbot, and not in 3rd person."
      ],
      "metadata": {
        "id": "zHpTg4nB2wss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "financial_prompt = \"\"\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-4ApwllP3FL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This template is needed by `RouterChain`."
      ],
      "metadata": {
        "id": "DWps8Owa99OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"\\\n",
        "Given a raw text input to a language model select the model prompt best suited for \\\n",
        "the input. You will be given the names of the available prompts and a description of \\\n",
        "what the prompt is best suited for. You may also revise the original input if you \\\n",
        "think that revising it will ultimately lead to a better response from the language \\\n",
        "model.\n",
        "\n",
        "<< FORMATTING >>\n",
        "Return a markdown code snippet with a JSON object formatted to look like:\n",
        "```json\n",
        "{{{{\n",
        "    \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\n",
        "    \"next_inputs\": string \\\\ A stringified JSON. Do not include the original input. It contains the following keys: the \"savings\" value, the \"debt\" value, the \"income\" value, and the \"summary\" provided above.\n",
        "}}}}\n",
        "```\n",
        "\n",
        "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR \\\n",
        "it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
        "REMEMBER: Make sure that \"next_inputs\" is not a string. This is very important!\n",
        "\n",
        "\n",
        "<< CANDIDATE PROMPTS >>\n",
        "{destinations}\n",
        "\n",
        "<< INPUT >>\n",
        "{{input}}\n",
        "\n",
        "<< OUTPUT (must include ```json at the start of the response) >>\n",
        "<< OUTPUT (must end with ```) >>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QCDSO-wmMpZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code creates the routing template"
      ],
      "metadata": {
        "id": "XEMrItYm-d6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = financial_prompt + MULTI_PROMPT_ROUTER_TEMPLATE"
      ],
      "metadata": {
        "id": "xe3TDApM-3lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destinations = [f\"{route['name']}: {route['description']}\" for route in routes]\n",
        "destinations_str = \"\\n\".join(destinations)\n",
        "router_template = prompt.format(destinations=destinations_str, level=level)"
      ],
      "metadata": {
        "id": "aXIPMLm3-f06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser(),\n",
        ")\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
      ],
      "metadata": {
        "id": "kea-sQDy-Wyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chains,\n",
        "    default_chain=ConversationChain(llm=llm, output_key=\"text\"),\n",
        "    verbose=False,\n",
        ")"
      ],
      "metadata": {
        "id": "C0z3UgdABhF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, try it! Write a code that:\n",
        "- Turns `langchain.debug` on so you could see what it going on.\n",
        "- Runs the `chain` we created above."
      ],
      "metadata": {
        "id": "V2Gr95RhBpYY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5UhcWBfLBrOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following questions:\n",
        "\n",
        "\n",
        "\n",
        "1.   Iteratively improve your code and prompts until you achieve the desired output.\n",
        "\n",
        "  - Does the final output match expectation? If not, what are the \"bugs\" from the client's perspective and what's your justification for their occurance?\n",
        "  - What \"extra mile\" you could have gone to improve results?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4aVVHXDx_DTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "LBfPC-KhbTwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. With the final chain, for each of the following scenarios, run the `chain` 10 times to sample the spectrum of generated answers:\n",
        "\n",
        "*   A `csv` where the debt is `$500` and the savings are `$4,000`, with a monthly income of `$4,000`\n",
        "*   A `csv` where the debt is `$500` and the savings are `$0`, with a monthly income of `$4,000`\n",
        "*   A `csv` where the debt is `$1,500` and the savings are `$4,000`, with an monthly income of `$3,000`\n",
        "\n"
      ],
      "metadata": {
        "id": "jMznDnYUbJxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run10times(csv_file):\n",
        "\n"
      ],
      "metadata": {
        "id": "iOXaS0VGbWbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Call for first scenario"
      ],
      "metadata": {
        "id": "vm2BfJxSb4Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Call for second scenario"
      ],
      "metadata": {
        "id": "WBxCACEMb5pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Call for third scenario"
      ],
      "metadata": {
        "id": "fWjf8yVdb5tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- State the expected correct output for each scenario in your own words.\n",
        "- What was the success rate for each scenario (as a percentage)? How did you calculate it?\n",
        "- Can you explain the low or high rate of success for each scenario? Comment, with suggestions when appropriate, on your findings."
      ],
      "metadata": {
        "id": "5i-ikW5qvpIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "qPdXK4v0ueVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2 (BONUS): FiniBot is online!"
      ],
      "metadata": {
        "id": "OBMXXSxuNGX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are now ready to start offering FiniBot services to the public! Here is what you need to do:\n",
        "\n",
        "Create a User interface using `streamlit` that consists of:\n",
        "- An `st.header` containing text welcoming your client and asking them to upload the spreadsheet. Provide a link to the spreadsheet's template in this header.\n",
        "- An [`st.file_uploader`](https://docs.streamlit.io/library/api-reference/widgets/st.file_uploader) \"Upload spreadsheet\" button. [This](https://stackoverflow.com/questions/68248125/how-to-read-csv-file-from-user-in-streamlit-and-converting-to-pandas-dataframe) may also be useful.\n",
        "- An [`st.radio`](https://docs.streamlit.io/library/api-reference/widgets/st.radio) toggle button to select whether the client is a \"Novice\" or an \"Expert\".\n",
        "- Displays the spreadsheet neatly, like [this](https://stackoverflow.com/questions/68248125/how-to-read-csv-file-from-user-in-streamlit-and-converting-to-pandas-dataframe).\n",
        "- An `st.markdown` to output FiniBot's analysis and recommendation.\n",
        "\n",
        "You may find [this cheatsheet](https://cheat-sheet.streamlit.app/) helpful while you are constructing your UI."
      ],
      "metadata": {
        "id": "BLr9LsTAPlKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create the app, follow these steps:\n",
        "\n",
        "1. Fork the [following GitHub](https://github.com/elhamod/IS883_Azure_OpenAI_demo/tree/Assignment3). You will be filling your code inside `app.py`\n",
        "2. Develop `streamlit`'s code as described above. You do not need to have language modeling at this point yet. You only need to have a functioning UX.\n",
        "3. Copy the code you have developed in Q1 to `app.py` and integrate it with `streamlit`'s code ***appropriately***. You will have to make some adjustments (e.g., getting the level from the toggle button rather than hard-coding it).\n",
        "4. Commit, push, and deploy!"
      ],
      "metadata": {
        "id": "hvpdMQRKtDBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some guides for working with Streamlit's community cloud:\n",
        "\n",
        "- For getting started and signing up (please follow only the first 8 steps): [Streamlit Community Cloud Quickstart](https://docs.streamlit.io/streamlit-community-cloud/get-started/quickstart)\n",
        "- For deploying from your GitHub repository: [Deploying to Streamlit Cloud](https://docs.streamlit.io/streamlit-community-cloud/deploy-your-app)\n",
        "- Make sure to add `OPENAI_API_KEY` in advanced settings"
      ],
      "metadata": {
        "id": "3YRRGwKCdfDB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cAe2H_fDcUdP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}