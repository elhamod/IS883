{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZE2kHQQYfnF0WMTBywsbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/IS883/blob/main/Prompt_Engineering_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Recap of How to use OpenAI API for chat: [GitHub](https://github.com/elhamod/IS883/blob/main/Open_Api_Guide.ipynb)"
      ],
      "metadata": {
        "id": "xfJfAyrYGKl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "2saCIkn6GlHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "jc3H9URqGdGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_ini_location = '/content/drive/MyDrive/Colab Notebooks/IS883/OpenAI guide/config.ini' # Change this to point to the location of your config.ini file.\n",
        "\n",
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(config_ini_location)\n",
        "openai_api_key = config['OpenAI']['API_KEY']"
      ],
      "metadata": {
        "id": "wG7zOShyGfar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Initialize the OpenAI API with your API key\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# You can set up your API key by harcdcoding it here. It is a hacky and bad practice as others will see your secret key clearly and use your account. But, can be used for trying something quick and dirty\n",
        "# openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  engine=\"text-davinci-003\",\n",
        "  prompt=\"Translate the following English text to Spanish: 'Hello, how are you?'\",\n",
        "  max_tokens=50\n",
        ")\n",
        "\n",
        "print(response.choices[0].text.strip())"
      ],
      "metadata": {
        "id": "si8CKtS6GJ1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Langchain Intro"
      ],
      "metadata": {
        "id": "DwQEZ_EZvag5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's use another package, [`langchain`](https://python.langchain.com/docs/get_started/introduction), that uses OpenAI API and allows for more advanced capabilities."
      ],
      "metadata": {
        "id": "jESCVMOwGyDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "et8bawp-Hl6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "y_6zZ1-cHgtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create the model"
      ],
      "metadata": {
        "id": "GKERwcNfvgC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key) #temperature=0.0, model=llm_model"
      ],
      "metadata": {
        "id": "6fR78FsAvjqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create the prompt \"template\" to translate from English to Spanish."
      ],
      "metadata": {
        "id": "u9_NAQUtvlUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "82iB5bQBHnsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the style of the translation"
      ],
      "metadata": {
        "id": "AO5LXwBQv5Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\"informal Spanish\"\"\""
      ],
      "metadata": {
        "id": "hswaYCstv5Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's query!"
      ],
      "metadata": {
        "id": "uPAtcPnzvsjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Hello, how are you?\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)\n",
        "\n",
        "\n",
        "print(\"Message: \", customer_messages)\n",
        "\n",
        "\n",
        "customer_response = chat(customer_messages)\n",
        "\n",
        "\n",
        "print(\"Response: \", customer_response.content)"
      ],
      "metadata": {
        "id": "vMvnL1vvvwuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting output from response\n",
        "\n",
        "Let's say I want to get some information about a travel essay and extract specific variables from it."
      ],
      "metadata": {
        "id": "tt0k-GF0wHO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "travel_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "source: Where I am travelling from.\n",
        "\n",
        "destination: Where I am travelling to.\n",
        "\n",
        "airline: Which airline I am travelling with.\n",
        "\n",
        "date: The date of travel in the format mm/dd/yyyy.\n",
        "\n",
        "price: How much I paid for the ticket.\n",
        "\n",
        "Format the output as JSON\n",
        "\n",
        "text: {text}\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(travel_template)"
      ],
      "metadata": {
        "id": "FOV1YRezdvHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay = \"\"\"\\\n",
        "On Veteran's day, I woke up reluctantly in my bed in Boston. I did not want to go to work.\\\n",
        "I decided to give myself time off and go on a vacation. I went on Expedia and bought a ticket to \\\n",
        "Houston to see my family. I took the plane, arrived safely, and spent a great logn weekend with my cousins. \\\n",
        "It was the best $500 I had spent in a while. The only downside is that JetBlue has lost my luggage. :(\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dy9KxjigeWhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query!"
      ],
      "metadata": {
        "id": "S_jO_ZPtwVpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt_template.format_messages(text=essay)\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "response = chat(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "vSXIaqMrfP-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the information."
      ],
      "metadata": {
        "id": "RTqiHhsvwXik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_object = json.loads(response.content)\n",
        "json_object['source']"
      ],
      "metadata": {
        "id": "Z3JrvG58gMCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using roles in OpenAI API"
      ],
      "metadata": {
        "id": "M0j7lxbvwbPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roles provide context to the model to answer properly and more specifically.\n",
        "\n",
        "- System role: defines that overarching context of the conversation.\n",
        "- user role: The human agent.\n",
        "- AI role: The AI bot."
      ],
      "metadata": {
        "id": "JP1UYTYKg7xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n"
      ],
      "metadata": {
        "id": "9Sv65YWWwoYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "\n",
        "# System role\n",
        "template = (\n",
        "    \"You are a teacher that is explaining advanced computer science concepts to someone in {degree}\"\n",
        ")\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "# Human role\n",
        "human_template = \"Explain to me what {concept} is.\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XRDAnJskhf-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [system_message_prompt, human_message_prompt]\n",
        ")\n",
        "\n",
        "# get a chat completion from the formatted messages\n",
        "print(chat(\n",
        "    chat_prompt.format_prompt(\n",
        "        degree=\"Computer science graduate program\", concept=\"RNN\"\n",
        "    ).to_messages()\n",
        ").content)"
      ],
      "metadata": {
        "id": "YxNxGurIw-Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A conversation with AI"
      ],
      "metadata": {
        "id": "JxNnht2TxKQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the memory capbility.\n",
        "\n"
      ],
      "metadata": {
        "id": "L4bUpXOHmE-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain.prompts import MessagesPlaceholder\n"
      ],
      "metadata": {
        "id": "oKGyCjdjmfgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Defines a system message\n",
        "template =  \"You are my buttler Alfred. You are talking to Batman\"\n",
        "system_message = SystemMessagePromptTemplate.from_template(template=template)\n",
        "PROMPT = PromptTemplate(input_variables=['history', 'input'], template=template + '.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:')\n",
        "\n",
        "# Defines a conversation\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    prompt=PROMPT,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")\n"
      ],
      "metadata": {
        "id": "mUibfx32mKrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.prompt"
      ],
      "metadata": {
        "id": "DdKsZDOqzeuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory"
      ],
      "metadata": {
        "id": "afnU9XnuxsHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ],
      "metadata": {
        "id": "VLBdFYqrm8SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"How old am I?\")"
      ],
      "metadata": {
        "id": "I-jNVNOAnV2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"No, my age is 39\")"
      ],
      "metadata": {
        "id": "DKBxG-nSniD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "id": "aTH1F3IWnqER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"When was I born?\")"
      ],
      "metadata": {
        "id": "RMk-gflH4KSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Who is my son?\")"
      ],
      "metadata": {
        "id": "cUjoJRzh4TCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.buffer"
      ],
      "metadata": {
        "id": "ZNn-685i45Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more debugging, wrap with `get_openai_callback()`"
      ],
      "metadata": {
        "id": "sifaLJVJxfqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    print(conversation.predict(input=\"Where are you now?\"))\n",
        "    print(cb)"
      ],
      "metadata": {
        "id": "RxiP6DXj5wxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as cb:\n",
        "    print(conversation.predict(input=\"Write a poem about the adventurs of Batman and Joker in 400 words\"))\n",
        "    print(cb)"
      ],
      "metadata": {
        "id": "WRouvFbx6O2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if I want to limit the buffer to a window of 3 exchanges?"
      ],
      "metadata": {
        "id": "_I9P_Jj2631-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "RZ4WZEq77QcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=10)\n",
        "\n",
        "template =  \"You are my buttler Alfred. You are talking to Batman\"\n",
        "system_message = SystemMessagePromptTemplate.from_template(template=template)\n",
        "PROMPT = PromptTemplate(input_variables=['history', 'input'], template=template + '.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:')\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    prompt=PROMPT,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")"
      ],
      "metadata": {
        "id": "VbAcjmBZ6_vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.predict(input=\"What's my name?\"))"
      ],
      "metadata": {
        "id": "nH8C-HS57Rgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.predict(input=\"Where am I?\"))"
      ],
      "metadata": {
        "id": "kfRd2ACc7Xom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.predict(input=\"I am now in Metropolis.\"))"
      ],
      "metadata": {
        "id": "NG_iwdIh7tcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.predict(input=\"Can you send me Robin?\"))"
      ],
      "metadata": {
        "id": "awGErgPB7fAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation.predict(input=\"Where am I?\"))"
      ],
      "metadata": {
        "id": "IiYliURG7obF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sequential chains\n",
        "\n",
        "We want to chain questions (The output of a question will be the input of another question)"
      ],
      "metadata": {
        "id": "ZSLuH28d8p3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://miro.medium.com/v2/resize:fit:828/format:webp/1*hdx24fJuQwWm1fT-ULGQhg.jpeg)"
      ],
      "metadata": {
        "id": "OMKux8KrZjJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "06sz9AqQ8sAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "\n",
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Give me the names of 10 different countries in {input}\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=chat, prompt=first_prompt)"
      ],
      "metadata": {
        "id": "sW_5TUOHA2CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Order the names in this by country size: {input}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=chat, prompt=second_prompt)"
      ],
      "metadata": {
        "id": "IvZMztPhA3Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                            #  verbose=True\n",
        "                                            )\n",
        "continent = \"North America\"\n",
        "overall_simple_chain.run(continent)"
      ],
      "metadata": {
        "id": "e1foO4-XA4vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the previous copde multiple times and see if there is anythin interesting."
      ],
      "metadata": {
        "id": "CXA6t5bzD4zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a somewhat more complicated chain:"
      ],
      "metadata": {
        "id": "NsP6LK1FDEVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain"
      ],
      "metadata": {
        "id": "Uw4B9wCZDD5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "AFzQgIK0E5rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "problem = \"\\\n",
        "John has some amount of apples, Sarah has double that amount, \\\n",
        "and Mohannad has 3 apples. If they altogether have 12 apples, how man y does John have?\\\n",
        "\""
      ],
      "metadata": {
        "id": "dc3z_brIFHW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Convert the following problem into an equation in terms of x, where x is the number of apples John has:\"\n",
        "    \"\\n\\n{problem}. Only give an equation\"\n",
        ")\n",
        "chain_one = LLMChain(llm=chat, prompt=first_prompt,\n",
        "                     output_key=\"Equation\", verbose=True\n",
        "                    )"
      ],
      "metadata": {
        "id": "5LIC1NhmE2KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"After solving the following equation in terms of x:\"\n",
        "    \"\\n\\n{Equation}, only provide the response as `x=`\"\n",
        ")\n",
        "chain_two = LLMChain(llm=chat, prompt=second_prompt,\n",
        "                     output_key=\"Solution\", verbose=True\n",
        "                    )\n"
      ],
      "metadata": {
        "id": "q1zKvpixBqWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Now, narrate how you solved this {problem} to a 6 year old\"\n",
        ")\n",
        "chain_three = LLMChain(llm=chat, prompt=third_prompt,\n",
        "                     output_key=\"narration\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "702m9_MxG8U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three],\n",
        "    input_variables=[\"problem\"],\n",
        "    output_variables=[\"Equation\", \"Solution\", \"narration\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "JXA8fYtMHVR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.debug = True # Useful for debugging the stages of the chain\n",
        "\n",
        "overall_chain(problem)"
      ],
      "metadata": {
        "id": "-7dV6BqSH-IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interacting with external data"
      ],
      "metadata": {
        "id": "HMk54JuFyRjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load a PDF and summarize the first page"
      ],
      "metadata": {
        "id": "EW9BW2ueN9H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "F6NXnWeFOA5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/MohannadCV.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "cr-mqduMN8xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = pages[0]"
      ],
      "metadata": {
        "id": "fi0hItddOVDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = \"Read the following page and summarize it in 50 words: \"+ p.page_content"
      ],
      "metadata": {
        "id": "9wsVq3K8P5-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m"
      ],
      "metadata": {
        "id": "Xb-U3N6rQAyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = False\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key)\n",
        "chat.predict(m)"
      ],
      "metadata": {
        "id": "FKe-uGkJOhpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agents!"
      ],
      "metadata": {
        "id": "tWxhw64MyY04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U wikipedia"
      ],
      "metadata": {
        "id": "A4acv-eR5cK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ask a question about GPT4 in Wikipedia"
      ],
      "metadata": {
        "id": "fmGRJPa9yfU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools, initialize_agent\n",
        "\n",
        "llm = ChatOpenAI(openai_api_key=openai_api_key) # temperature=0,  #model=llm_model\n",
        "tools = load_tools([\"wikipedia\"], llm=llm) #,\"llm-math\"\n",
        "\n",
        "agent= initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    verbose = True)\n",
        "\n",
        "msg = \"When was ChatGPT 4 released?\"\n",
        "\n",
        "agent(msg)"
      ],
      "metadata": {
        "id": "WWqM4Msn3tf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if we don't use Wikipedia agent?"
      ],
      "metadata": {
        "id": "hLJi9sIiyk3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage\n",
        "\n",
        "msgs = [HumanMessage(content=msg)]\n",
        "llm(msgs).content"
      ],
      "metadata": {
        "id": "QAN0cxMl5gSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We can also define our own agent."
      ],
      "metadata": {
        "id": "WFgoudJeyoPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define your own tool. The descriprion is what really tells the agent which tool to use."
      ],
      "metadata": {
        "id": "QCMTVbeV7nZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install DateTime"
      ],
      "metadata": {
        "id": "MhQIJVR87oxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import tool\n",
        "from datetime import date\n",
        "\n",
        "@tool\n",
        "def time(text: str) -> str:\n",
        "    \"\"\"Returns todays date, use this for any \\\n",
        "    questions related to knowing todays date. \\\n",
        "    The input should always be an empty string, \\\n",
        "    and this function will always return todays \\\n",
        "    date - any date mathmatics should occur \\\n",
        "    outside this function.\"\"\"\n",
        "    return str(date.today())"
      ],
      "metadata": {
        "id": "XN12GcJg7tli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent= initialize_agent(\n",
        "    [time], #tools +\n",
        "    llm,\n",
        "    # agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "bNsv5zPP7xFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"I ate a date. Will I be OK?\")"
      ],
      "metadata": {
        "id": "Ru547H-Z70qV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}