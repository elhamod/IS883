{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamod/IS883/blob/main/Week10/IS883_2024_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IS883 Week10: Tools and Agents"
      ],
      "metadata": {
        "id": "XOBPqcToTqFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use Google Colab for this assignment.\n",
        "\n",
        "2. **You are NOT allowed to use external or embedded Gen AI for this assignment (except where specifically instructed). However, you may use Google search and other online resources. As per the syllabus, you are required to cite your usage. You are also responsible for understanding the solution and defending it when asked in class.**\n",
        "\n",
        "3. For each question, fill in the answer in the cell(s) right below it. The answer could be code or text. You can add as many cells as you need for clarity.\n",
        "\n",
        "4. **Your submission on Blackboard should be the downloaded notebook (i.e., ipynb file). It should be prepopulated with your solution (i.e., the TA and/or instructor need not rerun the notebook to inspect the output). The code, when executed by the TA and/or instructor, should run with no runtime errors.**"
      ],
      "metadata": {
        "id": "FoUggC_UTa92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. In-Class Work"
      ],
      "metadata": {
        "id": "4mBWoSxpUNKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV7f5V1lX7j9",
        "outputId": "b42b9942-89ff-445f-a4c4-b1bfeffada1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.4)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Get the OpenAI API key\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('MyOpenAIKey')"
      ],
      "metadata": {
        "id": "qp-lE1g54XNv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Tools\n"
      ],
      "metadata": {
        "id": "QSNXa30eUPQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1.1 Using a Calculator for Accurate Computations."
      ],
      "metadata": {
        "id": "tAUWUyNc5498"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to get an answer to the following finantial problem:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "In your bank account, you have $110,345.45. Because you left them in a saving account with a high annual interest rate of %6.46, how much money will you have in a year?\n",
        "```\n",
        "\n",
        "The correct answer is $110,345.45 * 1.0646 = \\$117473.76607\n"
      ],
      "metadata": {
        "id": "HziH4cJmVvzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"In your bank account, you have $110,345.45. Because you left them in a saving account with a high annual interest rate of %6.46, how much money will you have in a year?\""
      ],
      "metadata": {
        "id": "Mi99uEnZUfkN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import Markdown\n",
        "\n",
        "### Create the chat agent\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o\")\n",
        "\n",
        "### Get the answer\n",
        "display(Markdown(chat.invoke(question).content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SYxUZwW_E4qE",
        "outputId": "902d96f8-903f-4dc5-f1b5-e591d786ac15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To calculate the amount of money you will have in a year with an annual interest rate of 6.46%, you can use the formula for compound interest, assuming the interest is compounded annually:\n\n\\[ A = P(1 + r)^n \\]\n\nWhere:\n- \\( A \\) is the amount of money accumulated after n years, including interest.\n- \\( P \\) is the principal amount (the initial amount of money).\n- \\( r \\) is the annual interest rate (decimal).\n- \\( n \\) is the number of years the money is invested or borrowed.\n\nIn this case:\n- \\( P = 110,345.45 \\)\n- \\( r = 0.0646 \\)\n- \\( n = 1 \\)\n\nPlug these values into the formula:\n\n\\[ A = 110,345.45 \\times (1 + 0.0646)^1 \\]\n\n\\[ A = 110,345.45 \\times 1.0646 \\]\n\n\\[ A = 117,468.77 \\]\n\nSo, after one year, you will have approximately $117,468.77 in your savings account."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Is the answer correct? What do you think is the cause for what you observe?"
      ],
      "metadata": {
        "id": "szJ9wuJDYReA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT only predicts tokens based on the text it has seen during training. It does not do any true calculations. As such, if this specific example is unlikely to have appeared in  training dataset, then the result is unlikely to be correct."
      ],
      "metadata": {
        "id": "IsAkLQ2eYbgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to upgrade the LLM's capabilities, we will use [`LLMMathChain`](https://medium.com/data-science-in-your-pocket/mathematics-using-llms-using-langchains-ca23bbd1a38b), which is a chain that uses a calculator tool, into our framework.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZzYTVov4Y3H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMMathChain\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "### You can turn on debugging using this code. You will be able to see the intermediate requests and responses.\n",
        "import langchain\n",
        "langchain.debug = False\n",
        "\n",
        "### Create the LLM\n",
        "llm = OpenAI(openai_api_key=openai_api_key)\n",
        "\n",
        "### Wrap the LLM with a chain that has access to the math tool.\n",
        "llm_math = LLMMathChain.from_llm(llm) #, verbose=True\n",
        "\n",
        "### Run the chain\n",
        "llm_math.invoke(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK48hwR2XDGR",
        "outputId": "b8b39b01-4cda-4844-fe5b-4001462bf2ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'In your bank account, you have $110,345.45. Because you left them in a saving account with a high annual interest rate of %6.46, how much money will you have in a year?',\n",
              " 'answer': 'Answer: 117473.76607'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What are the steps `LangChain` took to obtain the answer this time?\n",
        "\n",
        "*Hint: You may need some diagnostics...*"
      ],
      "metadata": {
        "id": "YZ_BLxcRctJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The LLM adds a prompt as a prefix to your question:\n",
        "\n",
        "\n",
        "```\n",
        "    \"Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\n",
        "    \\n\n",
        "    \\nQuestion: ${Question with math problem.}\n",
        "    \\n```text\n",
        "    \\n${single line mathematical expression that solves the problem}\n",
        "    \\n```\n",
        "    \\n...numexpr.evaluate(text)...\n",
        "    \\n\n",
        "    ```output\n",
        "    \\n${Output of running the code}\n",
        "    \\n```\n",
        "    \\nAnswer: ${Answer}\n",
        "    \\n\n",
        "    \\nBegin.\n",
        "    \\n\n",
        "    \\nQuestion: What is 37593 * 67?\n",
        "    \\n```text\n",
        "    \\n37593 * 67\n",
        "    \\n```\n",
        "    \\n...numexpr.evaluate(\\\"37593 * 67\\\")...\n",
        "    \\n```output\n",
        "    \\n2518731\n",
        "    \\n```\n",
        "    \\nAnswer: 2518731\n",
        "    \\n\n",
        "    \\nQuestion: 37593^(1/5)\n",
        "    \\n```text\\n37593**(1/5)\n",
        "    \\n```\n",
        "    \\n...numexpr.evaluate(\\\"37593**(1/5)\\\")...\n",
        "    \\n```\n",
        "    \\n8.222831614237718\n",
        "    \\n```\n",
        "    \\nAnswer: 8.222831614237718\n",
        "    \\n\n",
        "    \\nQuestion: In your bank account, you have $110,345.45. Because you left them in a saving account with a high annual interest rate of %6.46, how much money will you have in a year?\"\n",
        "```\n",
        "\n",
        "- It obtains the expression:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "text\n",
        "\\n110345.45 * 1.0646\n",
        "\\n```\n",
        "\\n...numexpr.evaluate(\\\"110345.45 * 1.0646\\\")...\n",
        "\\n\n",
        "```\n",
        "\n",
        "- It *executes* the expression as code (not through the LLM itself), and returns the answer."
      ],
      "metadata": {
        "id": "a4gSm9e8ctFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1.2 Tool Binding. Use-Case: Websearching Using Google Serper.\n",
        "\n"
      ],
      "metadata": {
        "id": "5foaGFZeA223"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's say we want a smart personal assistant bot that can browse the internet and be helpful.\n",
        "\n",
        "We will use [Google Serper](https://python.langchain.com/docs/integrations/tools/google_serper/), a *free* search tool.\n",
        "\n",
        "`LangChain` has some built-in [tools](https://python.langchain.com/docs/integrations/tools/) and [toolkits](https://python.langchain.com/v0.1/docs/integrations/toolkits/) that provide access to some useful functionality and APIs.\n",
        "\n",
        "The following [link](https://python.langchain.com/docs/how_to/tools_chain/) shows how to use tools in chains."
      ],
      "metadata": {
        "id": "v80I8OcOCsnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# question = \"Based on the weather today in Miami, do you think it is a good idea to go on a picnic?\"\n",
        "# question = \"I am at Questrom and hungry. give me 3 good noodle places near me?\"\n",
        "# question = \"What phone number should I call to talk to Mohannad Elhamod at Questrom?\"\n",
        "question = \"What is 1+1\""
      ],
      "metadata": {
        "id": "8vf1y3molEoc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "import os\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"), # To be used by the agent for intermediate operations.\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
        "\n",
        "# Setting up the Serper tool\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API')\n",
        "search = GoogleSerperAPIWrapper()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"GoogleSerper\",\n",
        "        func=search.run,\n",
        "        description=\"Useful for when you need to look up some information on the internet.\",\n",
        "    )\n",
        "]\n",
        "\n",
        "# Defining the agent\n",
        "agent = create_tool_calling_agent(chat, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) #, verbose=True\n",
        "\n",
        "print(\"Vanilla LLM answer:\", chat(question).content)\n",
        "\n",
        "# Run the agent\n",
        "print(\"*****\")\n",
        "print(\"Agent answer:\", agent_executor.invoke({\"input\": question})[\"output\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETmxyJvWEqoL",
        "outputId": "6f52a030-6969-49da-efea-0bb1bbb32327"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla LLM answer: 1 + 1 equals 2.\n",
            "*****\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m1 + 1 equals 2.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent answer: 1 + 1 equals 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1.3 Custom Tool Binding. Use-Case: What's the time?"
      ],
      "metadata": {
        "id": "VYuGSnMVBFWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we want out LLM to be aware of today's date. We want to implement our own date-checking function. This is done using `@tool` decorator.\n",
        "\n",
        "A tool expects some input parameters, if any, and returns some output. Here is some overview of [how tool calling is done](https://python.langchain.com/docs/concepts/tool_calling/#:~:text=A%20key%20principle%20of%20tool,result%20%3D%20llm_with_tools.). Here is a resource on how to build [custom tools](https://python.langchain.com/v0.1/docs/use_cases/tool_use/quickstart/).\n",
        "\n",
        "Reference: [`create_tool_calling_agent`](https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html)\n",
        "\n",
        "Reference: [custom tools](https://python.langchain.com/docs/how_to/custom_tools/)"
      ],
      "metadata": {
        "id": "QiSNddrpQk84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# question = \"What's the date today?\"\n",
        "question = \"Give a singer who is alive whose birthdate is next month\"\n",
        "# question = \"Give a celebrity whose birthdate is in 6 weeks\"\n",
        "# question = \"When was Michael Jackson born?\"\n",
        "# question = \"What day of the week is in 3 days?\"\n",
        "# question = \"What year is it?\"\n",
        "# question = \"I ate a date. Will I be OK?\"\n",
        "# question = \"What would be a good venue for a romantic date in Boston?\""
      ],
      "metadata": {
        "id": "v7w3f3zhUHNN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "import langchain\n",
        "langchain.debug = False\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Defining the tools\n",
        "from datetime import date, timedelta, datetime\n",
        "@tool\n",
        "def datetoday() -> str:\n",
        "    \"\"\"Returns today's date, use this for any \\\n",
        "    questions that need today's date to be answered. \\\n",
        "    This tool takes no argumetns but returns a string with today's date.\"\"\" #This is the desciption the agent uses to determine whether to use the time tool.\n",
        "    return \"Today is \" + str(date.today())\n",
        "\n",
        "tools = [datetoday]\n",
        "\n",
        "\n",
        "# Defining the agent\n",
        "agent = create_tool_calling_agent(chat, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) #\n",
        "\n",
        "\n",
        "print(\"Vanilla LLM answer:\", chat([HumanMessage(content=question)]).content)\n",
        "\n",
        "# # Run the agent\n",
        "print(\"*****\")\n",
        "print(\"Agent answer:\", agent_executor.invoke({\"input\": question})[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rwoca7-L91Z",
        "outputId": "491f39ac-b43d-4175-d5cf-1f2858b767ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla LLM answer: One singer who is alive and has a birthday next month is Taylor Swift, who was born on December 13, 1989.\n",
            "*****\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `datetoday` with `{}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mToday is 2024-11-18\u001b[0m\u001b[32;1m\u001b[1;3mNext month is December. A well-known singer who is alive and has a birthday in December is:\n",
            "\n",
            "- **Taylor Swift** - born on December 13, 1989.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent answer: Next month is December. A well-known singer who is alive and has a birthday in December is:\n",
            "\n",
            "- **Taylor Swift** - born on December 13, 1989.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Chain of Thought (CoT)"
      ],
      "metadata": {
        "id": "7rCYFJ4szjl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have seen in class before, breaking down a complex task into steps is useful as it generates intermediate steps, yielding a better and more accurate final answer.\n",
        "\n",
        "Here, we will take this idea further and apply *Chain of Thought (CoT)*, a prompt engineering technique that asks the model to \"reason\" through its answer by providing intermediate outputs.\n",
        "\n",
        "You may read this [reference](https://www.promptingguide.ai/techniques/cot) for more information."
      ],
      "metadata": {
        "id": "5Q5m9k-yFJeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.1 Do Objects Float. Yes or No?"
      ],
      "metadata": {
        "id": "SFgXNIesXmDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Would an avocado float in medical alcohol?\n",
        "\n",
        "The answer lies in object densities:\n",
        "* ethanol (grain alcohol):\t0.810\n",
        "*  [Avocado density](https://www.sciencedirect.com/science/article/pii/S0260877422002734): 1.02\n",
        "\n",
        "\n",
        "\n",
        "Let's try it out. We will use the `PromptTemplate` format to promote flexibilty (i.e., we may be interested in trying different liquids or objects).\n",
        "\n"
      ],
      "metadata": {
        "id": "Az6wftVTWCFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obj = \"avocado\"\n",
        "liquid = \"medical alcohol\""
      ],
      "metadata": {
        "id": "mwNQ7uBBW4MD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "instruction = \"Only provide the answer as a single yes or no without an explanation: \\n\"\n",
        "riddle = \"\"\"\n",
        "Would a {obj} float in {liquid}?\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
        "\n",
        "riddle_prompt_template =PromptTemplate(input_variables=[\"obj\", \"liquid\"], template=instruction + riddle)\n",
        "simple_chain = LLMChain(llm=chat, prompt=riddle_prompt_template)\n",
        "\n",
        "# print(\"Answer with no reasoning\")\n",
        "avg_cost = 0\n",
        "for i in range(10):\n",
        "  with get_openai_callback() as cb:\n",
        "    print(\"Answer: \", simple_chain.invoke({\"obj\":obj, \"liquid\":liquid})[\"text\"], \"Cost: $\", cb.total_cost)\n",
        "    avg_cost += cb.total_cost\n",
        "\n",
        "avg_cost = avg_cost/10\n",
        "print(\"Average cost: $\", avg_cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpl5nisMWjiR",
        "outputId": "c3bcdba0-2f22-471f-ca5d-1ffeeaa5e036"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  Yes. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  Yes. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  No. Cost: $ 5.7e-06\n",
            "Answer:  Yes. Cost: $ 5.7e-06\n",
            "Average cost: $ 5.7000000000000005e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "- What happens if I remove the instruction? Is that a problem?"
      ],
      "metadata": {
        "id": "lWr697NEXyNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.2 Do Objects Float? Can Gen AI figure it out?"
      ],
      "metadata": {
        "id": "s-jvgQp-YHAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's let `GPT-4o` do what it needs to do to get the answer without restraints, and then extract the answer and return it. We can do this using `LLMChain`s"
      ],
      "metadata": {
        "id": "PVKwP0gIZgZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o\")\n",
        "\n",
        "# riddle prompt where object and liquid are substituted.\n",
        "riddle_prompt =PromptTemplate(input_variables=[\"obj\", \"liquid\"], template=riddle).format_prompt(obj=obj, liquid=liquid)\n",
        "\n",
        "# The first chain solves the riddle.\n",
        "solver_prompt = PromptTemplate(\n",
        "    input_variables=[\"riddle\"], template=\"Solve the following riddle: {riddle}\"\n",
        ")\n",
        "solver_chain = LLMChain(llm=chat, prompt=solver_prompt)\n",
        "\n",
        "# The second chain extracts the final answer.\n",
        "extractor_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\"], template=\"Given the input, extract the answer as a yes or no with no explanation or additional text. Input: {input}\"\n",
        ")\n",
        "extractor_chain = LLMChain(llm=chat, prompt=extractor_prompt)\n",
        "\n",
        "# The overall chain\n",
        "ss_chain = SimpleSequentialChain(chains=[solver_chain, extractor_chain]) # ,verbose=True\n",
        "\n",
        "print(\"Answer with optional reasoning\")\n",
        "avg_cost = 0\n",
        "for i in range(10):\n",
        "  with get_openai_callback() as cb:\n",
        "    result = ss_chain.invoke(riddle_prompt)\n",
        "    print(\"Answer: \", result[\"output\"], \"Cost: $\", cb.total_cost)\n",
        "    avg_cost += cb.total_cost\n",
        "\n",
        "avg_cost = avg_cost/10\n",
        "print(\"Average cost: $\", avg_cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR2Z9f2vZf8_",
        "outputId": "68b97a25-6679-418e-a401-16a23da97e0e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer with optional reasoning\n",
            "Answer:  No Cost: $ 0.0016449999999999998\n",
            "Answer:  No Cost: $ 0.0016075\n",
            "Answer:  No Cost: $ 0.00252\n",
            "Answer:  No Cost: $ 0.00267\n",
            "Answer:  No Cost: $ 0.0017325\n",
            "Answer:  No Cost: $ 0.001945\n",
            "Answer:  No Cost: $ 0.0023325\n",
            "Answer:  No Cost: $ 0.0020825\n",
            "Answer:  No. Cost: $ 0.0026675\n",
            "Answer:  No Cost: $ 0.002845\n",
            "Average cost: $ 0.00220475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**\n",
        "\n",
        "What happens if we upgrade the model?"
      ],
      "metadata": {
        "id": "t2MSfO4vcy-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2.3 Do Objects Float? Can we nudge Gen AI to figure it out?"
      ],
      "metadata": {
        "id": "F66B1GDQd1_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we had to either increase cost or accept low performance. Can we do better by telling the model how to solve the problem?"
      ],
      "metadata": {
        "id": "UyA2E5ftd-HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions = \"\"\"\n",
        "- Follow these steps:\n",
        "1) what is the density of {obj}?\n",
        "1) what is the density of {liquid}?\n",
        "2) is density of  {obj} is less than a  {liquid} then yes, otherwise no.\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
        "\n",
        "# chain for substituting\n",
        "riddle_prompt =PromptTemplate(input_variables=[\"obj\", \"liquid\"], template=riddle + instructions).format_prompt(obj=obj, liquid=liquid)\n",
        "\n",
        "# The first chain solves the riddle.\n",
        "solver_prompt = PromptTemplate(\n",
        "    input_variables=[\"riddle\"], template=\"Solve the following riddle: {riddle}. \"\n",
        ")\n",
        "solver_chain = LLMChain(llm=chat, prompt=solver_prompt)\n",
        "\n",
        "# The second chain extracts the final answer.\n",
        "extractor_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\"], template=\"given the input, extract the answer as a yes or no with no explanation or additional text. Input: {input}\"\n",
        ")\n",
        "extractor_chain = LLMChain(llm=chat, prompt=extractor_prompt)\n",
        "\n",
        "# The overall chain\n",
        "ss_chain = SimpleSequentialChain(chains=[solver_chain, extractor_chain]) # ,verbose=True\n",
        "\n",
        "print(\"Answer with explicit reasoning\")\n",
        "avg_cost = 0\n",
        "for i in range(10):\n",
        "  with get_openai_callback() as cb:\n",
        "    result = ss_chain.invoke(riddle_prompt)\n",
        "    print(\"Answer: \", result[\"output\"], \"Cost: $\", cb.total_cost)\n",
        "    avg_cost += cb.total_cost\n",
        "\n",
        "avg_cost = avg_cost/10\n",
        "print(\"Average cost: $\", avg_cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo4bdEbQeZDR",
        "outputId": "98e3a602-79a5-441c-a272-f00cb40d4c62"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer with explicit reasoning\n",
            "Answer:  No Cost: $ 0.0001332\n",
            "Answer:  No Cost: $ 0.00013469999999999997\n",
            "Answer:  No Cost: $ 0.00015869999999999998\n",
            "Answer:  No Cost: $ 0.0001392\n",
            "Answer:  No Cost: $ 0.0001602\n",
            "Answer:  No Cost: $ 0.00018795000000000001\n",
            "Answer:  No Cost: $ 0.00014819999999999997\n",
            "Answer:  No Cost: $ 0.00013995000000000001\n",
            "Answer:  No Cost: $ 0.0001302\n",
            "Answer:  No Cost: $ 0.00015495\n",
            "Average cost: $ 0.000148725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many forms of *CoT* with mixed results. You may consult the following link for more [info](https://www.prompthub.us/blog/chain-of-thought-prompting-guide#automatic-chain-of-thought-prompting). You may try different forms and see how well they work.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-VkNjIWTAlor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 ReAct Framework"
      ],
      "metadata": {
        "id": "cn3gfD0XFqDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, answering a question may require *thinking* and then *acting* by using some tools. That is, the model may need to take several steps and obtain intermediate answers, just like in *CoT*. Some of these steps may require taking actions (i.e., using tools). This framework is called **ReAct (Reasoning-Acting)**.\n",
        "\n",
        "To create such a ReAct agent, we use the [`create_react_agent`](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent) function.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rt5SyufdQ-E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say our agent needs to answer a complex question that may require being broken down into several steps. For example, consider the following questions which may occur in a customer facing chatbot."
      ],
      "metadata": {
        "id": "YKQ9i2dwSK5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"look at the price of Microsoft stock. If I had bought 1 stock 3 years ago, how much money would I make today by selling?\" # Given today's date,\n",
        "\n",
        "\n",
        "# question = \"Create a task in my project with name LLMtest. The task's type is bug with name as tomorrow's date and assignee is mentormohannad@gmail.com\"\n",
        "# question = \"How many tasks are there with 2024-11-14 as a name in project with name LLMtest\"\n",
        "# question = \"How many tasks are there with yesterday's date as a name in project with name LLMtest\"\n",
        "# question = \"Who is the assignee of the task with yesterday's date as a name in project with name LLMtest\""
      ],
      "metadata": {
        "id": "qMexUX02Vrou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems to answer such questions, we need ReAct to reason and act using:\n",
        "\n",
        "1. A tool that is good at calculations.\n",
        "2. A tool that can search the internet.\n",
        "3. A tool that can find today's date.\n",
        "4. A tool that can read and create Jira issues.\n",
        "  *   For Jira, you simply need to [sign up](https://www.atlassian.com/try/cloud/signup?bundle=jira-software&edition=free&skipBundles=true) first, create a project and [get a token](https://id.atlassian.com/manage-profile/security) for authentication. After that, the [Jira toolkit](https://python.langchain.com/docs/integrations/tools/jira/) can be used.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AMOSCeI7WatI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  atlassian-python-api\n",
        "!pip install -qU langchain-community langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-oTjmtchuBa",
        "outputId": "8a5669a7-db3a-4a26-bac0-c33e4dcf71b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m153.6/177.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.9/177.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_community.llms import OpenAI\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, create_react_agent, create_tool_calling_agent, tool\n",
        "from langchain_community.tools.google_finance import GoogleFinanceQueryRun\n",
        "from langchain import LLMMathChain\n",
        "\n",
        "### Get the OpenAI API key\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('MyOpenAIKey')\n",
        "\n",
        "# LLM\n",
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "toHLcLrKVrpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## tool 1: getting today's date. Already defined above.\n",
        "from datetime import date, timedelta, datetime\n",
        "@tool\n",
        "def datetoday(dummy: str) -> str:\n",
        "    \"\"\"Returns today's date, use this for any \\\n",
        "    questions that need today's date to be answered. \\\n",
        "    This tool returns a string with today's date.\"\"\" #This is the desciption the agent uses to determine whether to use the time tool.\n",
        "    return \"Today is \" + str(date.today())"
      ],
      "metadata": {
        "id": "S2wWLFUqNQ2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## tool 2: Calculator.\n",
        "# We can simply define a tool that uses the LLMChain above\n",
        "llm = OpenAI(openai_api_key=openai_api_key)\n",
        "llm_math = LLMMathChain.from_llm(llm)\n",
        "@tool\n",
        "def calculator_tool(input_message: str) -> str:\n",
        "    \"\"\"Will not be used for any date arithmetics. Takes input message and performs the necessary calculations.\n",
        "    Returns the result.\"\"\" #This is the desciption the agent uses to determine whether to use the time tool.\n",
        "    return \"The answer to \" + input_message + \" is \" + llm_math.invoke(input_message)[\"answer\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5e4FLPaNQ4o",
        "outputId": "c9cfb340-247a-46e3-cfa2-5046400154eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-fe299cf11e23>:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(openai_api_key=openai_api_key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## tool 3: Internet Search.\n",
        "\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "import os\n",
        "\n",
        "# Setting up the Serper tool\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get('SERPER_API')\n",
        "search = GoogleSerperAPIWrapper()\n",
        "serper_tool = Tool(\n",
        "        name=\"GoogleSerper\",\n",
        "        func=search.run,\n",
        "        description=\"Useful for when you need to look up some information on the internet.\",\n",
        "    )\n"
      ],
      "metadata": {
        "id": "kABxvk3yQs7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## toolkit 1\n",
        "import os\n",
        "from langchain_community.agent_toolkits.jira.toolkit import JiraToolkit\n",
        "from langchain_community.utilities.jira import JiraAPIWrapper\n",
        "\n",
        "os.environ[\"JIRA_API_TOKEN\"] = userdata.get('JIRA_API_TOKEN')\n",
        "os.environ[\"JIRA_USERNAME\"] = \"mentormohannad@gmail.com\" #Email used to sign in to JIRA\n",
        "os.environ[\"JIRA_INSTANCE_URL\"] = \"https://mohannadelhamod.atlassian.net/\" #URL used to reach your free JIRA instance\n",
        "os.environ[\"JIRA_CLOUD\"] = \"True\"\n",
        "\n",
        "jira = JiraAPIWrapper()\n",
        "toolkit = JiraToolkit.from_jira_api_wrapper(jira)\n",
        "\n",
        "# DON'T CHANGE: Some fixes and improvements needed.\n",
        "for idx, tool in enumerate(toolkit.tools):\n",
        "    toolkit.tools[idx].name = toolkit.tools[idx].name.replace(\" \", \"_\")\n",
        "toolkit.tools[2].description = toolkit.tools[2].description + \". Don't set priority for issues. Make sure to specify the project ID.\" # Future work: could set the assignee to {'accountId':'account_id'}\n"
      ],
      "metadata": {
        "id": "idVwaJamNagf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's put the tools together"
      ],
      "metadata": {
        "id": "s69_uwB6OUuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    datetoday,\n",
        "    calculator_tool,\n",
        "    serper_tool\n",
        "] + toolkit.get_tools()"
      ],
      "metadata": {
        "id": "k5DAFkJYOWzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the different tools available"
      ],
      "metadata": {
        "id": "YdpsaE6wNykw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, tool in enumerate(tools):\n",
        "    print(f\"Tool {idx}: {tool.name}\")\n",
        "    print(\"Description:\", tool.description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwxgsCTk5sJk",
        "outputId": "9f03b374-9d5a-40a7-a892-7811fb1092f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool 0: datetoday\n",
            "Description: Returns today's date, use this for any     questions that need today's date to be answered.     This tool returns a string with today's date.\n",
            "Tool 1: calculator_tool\n",
            "Description: Will not be used for any date arithmetics. Takes input message and performs the necessary calculations.\n",
            "    Returns the result.\n",
            "Tool 2: GoogleSerper\n",
            "Description: Useful for when you need to look up some information on the internet.\n",
            "Tool 3: JQL_Query\n",
            "Description: \n",
            "    This tool is a wrapper around atlassian-python-api's Jira jql API, useful when you need to search for Jira issues.\n",
            "    The input to this tool is a JQL query string, and will be passed into atlassian-python-api's Jira `jql` function,\n",
            "    For example, to find all the issues in project \"Test\" assigned to the me, you would pass in the following string:\n",
            "    project = Test AND assignee = currentUser()\n",
            "    or to find issues with summaries that contain the word \"test\", you would pass in the following string:\n",
            "    summary ~ 'test'\n",
            "    \n",
            "Tool 4: Get_Projects\n",
            "Description: \n",
            "    This tool is a wrapper around atlassian-python-api's Jira project API, \n",
            "    useful when you need to fetch all the projects the user has access to, find out how many projects there are, or as an intermediary step that involv searching by projects. \n",
            "    there is no input to this tool.\n",
            "    \n",
            "Tool 5: Create_Issue\n",
            "Description: \n",
            "    This tool is a wrapper around atlassian-python-api's Jira issue_create API, useful when you need to create a Jira issue. \n",
            "    The input to this tool is a dictionary specifying the fields of the Jira issue, and will be passed into atlassian-python-api's Jira `issue_create` function.\n",
            "    For example, to create a low priority task called \"test issue\" with description \"test description\", you would pass in the following dictionary: \n",
            "    {{\"summary\": \"test issue\", \"description\": \"test description\", \"issuetype\": {{\"name\": \"Task\"}}, \"priority\": {{\"name\": \"Low\"}}}}\n",
            "    . Don't set priority for issues. Make sure to specify the project ID.\n",
            "Tool 6: Catch_all_Jira_API_call\n",
            "Description: \n",
            "    This tool is a wrapper around atlassian-python-api's Jira API.\n",
            "    There are other dedicated tools for fetching all projects, and creating and searching for issues, \n",
            "    use this tool if you need to perform any other actions allowed by the atlassian-python-api Jira API.\n",
            "    The input to this tool is a dictionary specifying a function from atlassian-python-api's Jira API, \n",
            "    as well as a list of arguments and dictionary of keyword arguments to pass into the function.\n",
            "    For example, to get all the users in a group, while increasing the max number of results to 100, you would\n",
            "    pass in the following dictionary: {{\"function\": \"get_all_users_from_group\", \"args\": [\"group\"], \"kwargs\": {{\"limit\":100}} }}\n",
            "    or to find out how many projects are in the Jira instance, you would pass in the following string:\n",
            "    {{\"function\": \"projects\"}}\n",
            "    For more information on the Jira API, refer to https://atlassian-python-api.readthedocs.io/jira.html\n",
            "    \n",
            "Tool 7: Create_confluence_page\n",
            "Description: This tool is a wrapper around atlassian-python-api's Confluence \n",
            "atlassian-python-api API, useful when you need to create a Confluence page. The input to this tool is a dictionary \n",
            "specifying the fields of the Confluence page, and will be passed into atlassian-python-api's Confluence `create_page` \n",
            "function. For example, to create a page in the DEMO space titled \"This is the title\" with body \"This is the body. You can use \n",
            "<strong>HTML tags</strong>!\", you would pass in the following dictionary: {{\"space\": \"DEMO\", \"title\":\"This is the \n",
            "title\",\"body\":\"This is the body. You can use <strong>HTML tags</strong>!\"}} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see the thinking and acting in motion!"
      ],
      "metadata": {
        "id": "JJT2iRrZOZR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### You can turn on debugging using this code. You will be able to see the intermediate requests and responses.\n",
        "import langchain\n",
        "langchain.debug = False\n",
        "\n",
        "# The following prompt is designed for ReAct framework.\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "agent = create_react_agent(chat, tools, prompt) # Now we have a ReAct agent!\n",
        "\n",
        "# We may still use create_tool_calling_agent and get good result. But, it is not following the standard ReAct framework per se.\n",
        "# More on agent types can be found here: https://python.langchain.com/v0.1/docs/modules/agents/agent_types/\n",
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "# prompt = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         (\"system\", \"You are a helpful assistant.\"),\n",
        "#         (\"human\", \"{input}\"),\n",
        "#         (\"placeholder\", \"{agent_scratchpad}\"), # To be used by the agent for intermediate operations.\n",
        "#     ]\n",
        "# )\n",
        "# agent = create_tool_calling_agent(chat, tools, prompt)\n",
        "\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose= True, stream_runnable=False)\n",
        "agent_executor.invoke({\"input\": question}, handle_parsing_errors=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEdvX6OmOdal",
        "outputId": "22769673-19c3-41df-a76c-86c295682974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo answer this question, I need to first look up the current price of Microsoft stock and then find its price from three years ago. I'll calculate the difference to determine how much money would have been made by selling the stock today. \n",
            "\n",
            "Action: GoogleSerper  \n",
            "Action Input: \"current Microsoft stock price\"  \u001b[0m\u001b[38;5;200m\u001b[1;3m415.25 +0.25 (0.06%)\u001b[0m\u001b[32;1m\u001b[1;3mTo determine how much money would have been made by selling the stock today, I still need to find the stock price of Microsoft from three years ago. I'll proceed to look that up next.\n",
            "\n",
            "Action: GoogleSerper  \n",
            "Action Input: \"Microsoft stock price 3 years ago\"  \u001b[0m\u001b[38;5;200m\u001b[1;3m415.25 +0.25 (0.06%)\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the current stock price of Microsoft is 415.25, but I need to confirm the stock price from three years ago to calculate the profit. The observation didn't provide the historical price directly, so I'll search for the specific stock price from three years ago.\n",
            "\n",
            "Action: GoogleSerper  \n",
            "Action Input: \"Microsoft stock price on [date three years ago]\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mDiscover historical prices for MSFT stock on Yahoo Finance. View daily, weekly or monthly format back to when Microsoft Corporation stock was issued. An investor who bought $1000 worth of Microsoft stock at the IPO in 1986 would have $6881255 today, roughly 6881 times their original investment - a 25.43% ... Find the latest historical data for Microsoft Corporation Common Stock (MSFT) at Nasdaq.com. View historical data in a monthly, bi-annual, or yearly format. Get free historical data for MSFT. You'll find the closing price, open, high, low, change and %change of the Microsoft Corporation Stock for the selected range ... The closing price for Microsoft (MSFT) between November 13, 1999 and November 13, 2024 is $423.03, yesterday. It is up 1,453.6% in that time. The latest price ... Missing: ago] | Show results with:ago]. Microsoft Stock Price History ; 9/4/2024, $408.90, $405.91 ; 9/3/2024, $409.44, $417.91 ; 8/30/2024, $417.14, $415.60 ; 8/29/2024, $413.12, $414.94 ... Microsoft Corp. historical stock charts and prices, analyst ratings, financials, and today's real-time MSFT stock price. Microsoft Stock Price Lookup. Historic Stock Lookup ... since the date shown. The closing price is not necessarily indicative of future price performance. The closing price for Microsoft (MSFT) between 2014 and 2024 is $426.89, yesterday. It is up 1264.7% in that time. The latest price is $414.59. In depth view into Microsoft Price including historical data from 1986, charts and stats. Missing: ago] | Show results with:ago].\u001b[0m\u001b[32;1m\u001b[1;3mIt looks like I didn't get the specific historical price from the observations. I need to refine my search to focus on the specific date three years ago to find the exact stock price of Microsoft at that time.\n",
            "\n",
            "Action: GoogleSerper  \n",
            "Action Input: \"Microsoft stock price on [date three years ago]\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mDiscover historical prices for MSFT stock on Yahoo Finance. View daily, weekly or monthly format back to when Microsoft Corporation stock was issued. An investor who bought $1000 worth of Microsoft stock at the IPO in 1986 would have $6881255 today, roughly 6881 times their original investment - a 25.43% ... Find the latest historical data for Microsoft Corporation Common Stock (MSFT) at Nasdaq.com. View historical data in a monthly, bi-annual, or yearly format. Get free historical data for MSFT. You'll find the closing price, open, high, low, change and %change of the Microsoft Corporation Stock for the selected range ... The closing price for Microsoft (MSFT) between November 13, 1999 and November 13, 2024 is $423.03, yesterday. It is up 1,453.6% in that time. The latest price ... Missing: ago] | Show results with:ago]. Microsoft Stock Price History ; 9/4/2024, $408.90, $405.91 ; 9/3/2024, $409.44, $417.91 ; 8/30/2024, $417.14, $415.60 ; 8/29/2024, $413.12, $414.94 ... The closing price for Microsoft (MSFT) between October 28, 2004 and October 28, 2024 is $428.15, on Friday. It is up 2,340.9% in that time. The latest price ... Missing: ago] | Show results with:ago]. Microsoft Corp. historical stock charts and prices, analyst ratings, financials, and today's real-time MSFT stock price. Microsoft Stock Price Lookup. Historic Stock Lookup ... since the date shown. The closing price is not necessarily indicative of future price performance. In depth view into Microsoft Price including historical data from 1986, charts and stats. Missing: ago] | Show results with:ago].\u001b[0m\u001b[32;1m\u001b[1;3mIt appears that I'm still not obtaining the specific historical price for Microsoft stock from three years ago. I will now try a more direct approach to find the stock price from that specific date.\n",
            "\n",
            "Action: GoogleSerper  \n",
            "Action Input: \"Microsoft stock price October 2020\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mDiscover historical prices for MSFT stock on Yahoo Finance. View daily, weekly or monthly format back to when Microsoft Corporation stock was issued. Discover historical prices for MSFT stock on Yahoo Finance. View daily, weekly or monthly format back to when Microsoft Corporation stock was issued. The closing price for Microsoft (MSFT) between 1995 and 2020 was $215.43, on December 31, 2020. It was up 8,981.6% in that time. The latest price is $415.03. The Microsoft 52-week high stock price is 468.35, which is 12.9% above the current share price. The Microsoft 52-week low stock price is 362.90, which is 12.6% ... Microsoft Stock Price Lookup. Historic Stock Lookup. Lookup Month. January, February, March, April, May, June, July, August, September, October ... 2020, 2021 ... December 2020, $215.42, $222.42. November 2020, $207.34, $214.07. October 2020, $195.59, $202.47. September 2020, $203.18, $210.33. August 2020, $217.87 ... The closing price for Microsoft (MSFT) on October 9, 2020 was $208.48. It was up 2.2% for the day. The latest price is $428.15. Find the latest historical data for Microsoft Corporation Common Stock (MSFT) at Nasdaq.com. View historical data in a monthly, bi-annual, or yearly format. Microsoft Corp. historical stock charts and prices, analyst ratings, financials, and today's real-time MSFT stock price. Missing: 2020 | Show results with:2020. Microsoft Stock Price History ; 11/6/2020, $223.72, $222.13 ; 10/30/2020, $202.47, $203.64 ; 10/23/2020, $216.23, $214.96 ; 10/16/2020, $219.66, $220.42 ...\u001b[0m\u001b[32;1m\u001b[1;3mI'm still not obtaining the precise historical price for Microsoft stock on the specific date three years ago. However, I did find that the stock price in October 2020 was around $195.59 to $202.47. I'll take the last known price in October 2020, which was $202.47, and compare it to the current price of $415.25 to calculate the profit.\n",
            "\n",
            "Action: calculator_tool  \n",
            "Action Input: \"415.25 - 202.47\"  \u001b[0m\u001b[33;1m\u001b[1;3mThe answer to 415.25 - 202.47 is Answer: 212.78\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
            "\n",
            "Final Answer: If you had bought 1 Microsoft stock three years ago at a price of approximately $202.47, you would make a profit of $212.78 by selling it today at the current price of $415.25.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'look at the price of Microsoft stock. If I had bought 1 stock 3 years ago, how much money would I make today by selling?',\n",
              " 'output': 'If you had bought 1 Microsoft stock three years ago at a price of approximately $202.47, you would make a profit of $212.78 by selling it today at the current price of $415.25.'}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Conversations with AI"
      ],
      "metadata": {
        "id": "Qz_74DjpJeSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Homework"
      ],
      "metadata": {
        "id": "EJIUrg_yUuJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1 Creating and Dating Files"
      ],
      "metadata": {
        "id": "Gl891Vbjb70L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write an agent that solves the following question correctly:\n",
        "\n",
        "> Create a file named *\\<some filename\\>*.txt and contains today's date.\n",
        "\n",
        "Once it executes, the agent will be able to create the file with the correct name and content. It should create the file under `/content`. It will show up on the left side of your Google notebook under *files*. **(5 Points)**\n",
        "\n",
        "You will need to find and integrate the right tool from this [list](https://python.langchain.com/docs/integrations/tools/) to be able to create and write a file.\n",
        "\n",
        "You will also need to use the `datetoday` tool we defined previously to get today's date.\n",
        "\n",
        "Make sure you allow the agent to use multiple tools.\n",
        "```\n",
        "tools = [tool1, tool2]\n",
        "```"
      ],
      "metadata": {
        "id": "dFY32l5XUx1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**"
      ],
      "metadata": {
        "id": "MPwWcmlvcEib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "ncCQGeMphSG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"hello.txt\""
      ],
      "metadata": {
        "id": "ROGOAApQgVm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here write an instruction prompt that effectively execute the desired functionality. Remember that `filename` is a *variable*. **(3 Points)**"
      ],
      "metadata": {
        "id": "WRFDAZQwhBiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = ### Fill in code here"
      ],
      "metadata": {
        "id": "DCMMfIYFhB9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(openai_api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
        "\n",
        "# Create the PromptTemplate from the instruction you defined above.\n",
        "instruction_template =PromptTemplate(\n",
        "    input_variables= ### Fill in code here\n",
        "    template=instruction\n",
        "    )"
      ],
      "metadata": {
        "id": "NugPgsnUU2PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the first tool that gets today's date"
      ],
      "metadata": {
        "id": "cOHRtlwAhpTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date, timedelta, datetime\n",
        "@tool\n",
        "def datetoday() -> str:\n",
        "    \"\"\"Returns today's date, use this for any \\\n",
        "    questions that need today's date to be answered. \\\n",
        "    This tool takes no argumetns but returns a string with today's date.\"\"\" #This is the desciption the agent uses to determine whether to use the time tool.\n",
        "    return \"Today is \" + str(date.today())"
      ],
      "metadata": {
        "id": "M4fHhojwhpZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the second tool that is able to create and write the file. **(7 Points)**"
      ],
      "metadata": {
        "id": "i3MVPHGuhyNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def filewriter(filename: str, content: str) -> str:\n",
        "    ### Fill here: Provide tool description here, including expected parameters and their meaning.\n",
        "\n",
        "    ####\n",
        "    # Write\n",
        "    # Tool\n",
        "    # Code\n",
        "    # Here\n",
        "    ####\n",
        "\n",
        "    return ### File here: Write code here that returns the result of the tool"
      ],
      "metadata": {
        "id": "6OcPP4ouhyV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting it all together.\n",
        "When you run the code, *make sure it shows the intermedate tool calls*. **(4 Points)**"
      ],
      "metadata": {
        "id": "pRODohkRidVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = ### Fill here: Since both tools should be available, place them into a list.\n",
        "\n",
        "# Defining the agent\n",
        "### You may need to make minor changes here.\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "agent = create_tool_calling_agent(chat, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools) # , verbose=True\n",
        "\n",
        "formatted_instruction = ### Fill code here\n",
        "print(\"Agent answer:\", agent_executor.invoke({\"input\": formatted_instruction})[\"output\"])"
      ],
      "metadata": {
        "id": "HgJX4wn9fifc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}