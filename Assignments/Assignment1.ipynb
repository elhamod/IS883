{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "## Overview\n",
    "This notebook has been created for IS883 at Questrom School of Business - Boston University. It is designed to guide students through the basics of machine learning and language modeling.\n",
    "\n",
    "### Created By\n",
    "- **Author:** Mohannad Elhamod\n",
    "- **Position:** Clinical Assistant Profressor\n",
    "- **Institution:** Questrom School of Business - Boston University\n",
    "\n",
    "\n",
    "\n",
    "*Note: This notebook is intended for educational purposes and is part of the coursework for IS883. Unauthorized distribution or use is not permitted.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Don't forget to copy the notebook to your own student directory on SCC (i.e., `/projectnb/is883/students/xxxx/`) _You will lose your work if you forget! Alternatively, you could use Google Colab if your prefer._**\n",
    "\n",
    "For each question, fill in the answer in the cell(s) right below it. The answer could be code or text. You can add as many cells as you need for clarity.\n",
    "\n",
    "Enter your BUID (only numerical part) below.\n",
    "\n",
    "You are free to use SCC or Google Colab. Your submission on Blackboard should be this notebook, including the generated output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUID = 123456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Machine learning is generally stochastic, meaning you get different results for different runs. To avoid that, you can \"seed\" your code. For this assignment, your first task is to use your BU id (only the numeric part) as a seed for all random number generators. The true test is whether you get exactly the same result for every single run of this notebook. __(0.25 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Diagnosis of Diabetes\n",
    "\n",
    "In this part, we will be working with medical data to profile patients with diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the file `diabetes1.csv`, display the dataset in a tabular format. Display the statistics of this table as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. You will first use a decision tree to model the data (i.e., the input will be the patient attributes, and the `outcome` will be whether someone is diabetic or not.). You will use:\n",
    "\n",
    "    ```python\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.tree import plot_tree\n",
    "    ```\n",
    "\n",
    "    to train and visualize the tree. You will try the following different tree sizes (i.e., leaves): {2, 5, 10, 20, 30, 40, 50}.\n",
    "\n",
    "- You will plot the training and test errors as two lines, with the x axis as the number of leaves. Format your plot properly with legends and colors. __(0.25 points)__\n",
    "- Can you identify from the plot which models are overfitting, underfitting, or fit well? Elaborate. __(0.5 points)__\n",
    "- what does the number of leaves represent in machine learning lingo as discussed in class? Elaborate. __(0.25 points)__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, you will use a neural network to model the data.\n",
    "\n",
    "- Design your MLP architecture to be compatible with the input/output format. __(0.25 points)__\n",
    "- Perform any necessary data pre-processing. __(0.25 points)__\n",
    "- After splitting the dataset **randomly** into 80% training and 20% test sets, create and train an MLP that fits your model well. You will have to make decisions including the size of the model and other hyper-parameters (e.g., the learning rate). Explain every single such decision you make. __(0.5 points)__\n",
    "- How did you arrive to the conclusion that your model is a good fit? Show your work and reasoning. __(0.25 points)__\n",
    "- Describe any particular pain points you have faced searching for this _\"best model\"_. __(0.25 points)__\n",
    "- Is your neural network result better or worse than the best decision tree you got? Explain how you reached that conclusion. __(0.25 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You will now test your best model on another diabetes dataset `diabetes2.csv`.\n",
    " \n",
    "- How does the model perform on this second dataset compared to the test set from the first dataset? __(0.25 points)__\n",
    "- Can you explain the difference in performance? What do you think the root cause is? Show how you arrived at that conclusion. __(0.25 points)__\n",
    "- Reflect on your results and explain, with an example, how such a discrepancy can occur in a real-world scenario. What are the consequences? What are the potential remedies? __(0.25 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Reflection Question\n",
    "\n",
    "In order to measure how well machine learning could be used for legal assistance, the bar association has hired you to curate a dataset of a large corpora of legal documents for training and testing different machine learning models. Once the dataset is curated [(e.g. this)](https://www.kaggle.com/datasets/anudit/india-legal-cases-dataset), many researchers and practitioners will bid and use the publicized dataset to demonstrate the superiority of their model. \n",
    "\n",
    "1. Can you think of a potential issue with such a practice in terms of model quality? __(0.25 points)__\n",
    "2. Can you suggest remedies that are easy to implement for such issue(s)? __(0.25 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Looking at the training code we used in `/projectnb/is883/projects/Week1/is883_week1.ipynb`, you can see that we have kept track of the model that performs best _on the training set_. \n",
    "\n",
    "- Can you think of any potential issues with such an approach? Elaborate. __(0.25 points)__\n",
    "- Is there a way to keep track of a better model? Elaborate. __(0.25 points)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: N-grams\n",
    "\n",
    "Let's do some language modeling! In this section, you will create some n-grams and experiment with how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find a Python package that helps you create n-grams. You are free to use any package you desire. Feel free to Google or use ChatGPT to find the package that is easiest to use. Install the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For each of the following sentences, create a bigram.\n",
    "\n",
    "        - \"to be or not to be. that is the question!\"\n",
    "        - \"Ask not what your country can do for you. Ask what you can do for your country.\"\n",
    "        - \"is this the real life? is this just fantasy?\"\n",
    "\n",
    "- For each sentence, show the bigram you have constructed (i.e., the dictionary). __(0.25 points)__\n",
    "- Based on each bigram, generate 10 new sentences by __sampling__ the dictionary. What do you notice about these sentences? Explain why you think your observation(s) is/are interesting. __(0.5 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You will upload and read the file `Week1-ngrams.txt`. You will create the following __n-grams__, where n ={2, 3, 4, 5, 10}. You will then, using each n-gram, generate a text of similar length to the original file.\n",
    "\n",
    "- Compare the different generated texts. What observations do you make? Explain your observations with examples. __(0.5 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now, construct a __\"reveresed n-gram\"__. Meaning, you will construct n-grams that take right-to-left context (i.e., start with the last word and predict backwards). How does the quality of the reverse-generated text compare to that generated using vanilla n-grams? Comment and explain with examples. __(0.5 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finally, calculate the perplexity for all models and reverse-models. Comment on the results and elaborate on your findings. __(0.5 points)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
